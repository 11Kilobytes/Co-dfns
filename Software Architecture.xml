<?xml version="1.0" encoding="utf-8" ?>

<article xmlns="http://docbook.org/ns/docbook" version="5.0">
  <info>
    <author>Aaron W. Hsu</author>
    <date>Monday, October 7th, 2013</date>
  </info>
  <section>
    <title>Co-Dfns Software Architecture</title>
    <simpara>
      This document describes the high-level system architecture of the 
      Co-Dfns compiler at the module and top levels. This includes the 
      high-level design of passes and their box-based specifications, the 
      programming approach used to develop each of the passes and the 
      methodology of handling state-box specifications.
    </simpara>
    <simpara>
      The methodology for handling the state-based specifications are 
      different and differ from the practices found in normal box-structure 
      methods. This is because the overal design favors a pure-functional 
      approach, or one that is externally functional for any given level 
      of abstraction. This necessitates no change in the clear or black 
      box specifications, but requires a different approach for state-based 
      structured specification and design. The <citetitle>Cleanroom Engineering Guide</citetitle>
      documents this new approach for those who wish to understand it in more 
      detail as it is understood within the scope of this project.
    </simpara>
    <simpara>
      After reading this document, the approach, design, and structure of the compiler 
      should be evident, and it should be possible to navigate source files without 
      difficulty or to understand the reasoning behind the creation of certain essential 
      functions or how they fit together. The dependencies, orderings, and relationships 
      between functions and elements should be clear, as should be the expectations and 
      implied elements not clearly documented in the source code itself. Developers who 
      wish to understand the source code should rely heavily on this document as the 
      main document that guides the structure and implementation of the compiler. 
    </simpara>
    <section>
      <title>Asset Analysis</title>
      <simpara>
        The <citetitle>Software Development Plan</citetitle> identifies four to five 
        major influences on the Software architecture: LLVM, MiniKanren, Nanopass, and 
        prototypes implemented in C, C++, and Dyalog APL. MiniKanren is a specific implementation 
        suggestion for a specific component of the compiler, and as such plays a less 
        significant role in the Software Architecture. The other components, however, play 
        a very significant role in the design of the software, and this section documents 
        the analysis of these elements as they relate to the design of the system. There 
        is a sub-section dedicated to each of these assets as well as specific sections to 
        deal with analysis of the <citetitle>Function Specification</citetitle> and other 
        miscellaneous assets.
      </simpara>
      <itemizedlist spacing="compact">
        <title>Summary of Analysis</title>
        <listitem>
          <simpara>[NanoPass] Compiler should use a single unified grammar</simpara>
        </listitem>
        <listitem>
          <simpara>[NanoPass] Use a formal verification of the correctness of each compiler pass</simpara>
        </listitem>
        <listitem>
          <simpara>[NanoPass] Use small, numerous compiler passes rather than large, monolithic passes</simpara>
        </listitem>
        <listitem>
          <simpara>[NanoPass] Use aggregate, pure-functional programming as much as possible</simpara>
        </listitem>
        <listitem>
          <simpara>[NanoPass] Global state is okay, but should remain immutable throughout a given compiler invocation</simpara>
        </listitem>
        <listitem>
          <simpara>[Parsing] Most of the parsing of Co-Dfns is regular</simpara>
        </listitem>
        <listitem>
          <simpara>[Parsing] There are specific cases of necessary recursions</simpara>
        </listitem>
        <listitem>
          <simpara>[Parsing] There are simple, but necessary needs for muli-pass refinements of the parsing</simpara>
        </listitem>
        <listitem>
          <simpara>[Parsing] The parser must use passes to extract type information for variables in order to eliminate most ambiguity</simpara>
        </listitem>
        <listitem>
          <simpara>[Parsing] Some instance of ambiguity will remain</simpara>
        </listitem>
        <listitem>
          <simpara>[Parsing] The grammar will need to take into account those instances of ambiguity that cannot be eliminated</simpara>
        </listitem>
        <listitem>
          <simpara>[Parsing] Most of the parser should be able to use aggregate style programming to express the parsing stages clearly</simpara>
        </listitem>
        <listitem>
          <simpara>[Runtime] Runtime should provide facilities for array class promotion</simpara>
        </listitem>
        <listitem>
          <simpara>[Runtime] It might make sense to have individual scalar operations in C</simpara>
        </listitem>
        <listitem>
          <simpara>[Runtime] Scalar functions are probably best implemented in Co-Dfns</simpara>
        </listitem>
        <listitem>
          <simpara>[Runtime] Most of the primitive functions and operators should be implemented in Co-Dfns, not in the runtime</simpara>
        </listitem>
        <listitem>
          <simpara>[Runtime] Implementation language of the core runtime should be C</simpara>
        </listitem>
        <listitem>
          <simpara>[Runtime] Runtime should take cache behavior into account</simpara>
        </listitem>
        <listitem>
          <simpara>[Runtime] The compiler should try to mitigate the cost of a function call</simpara>
        </listitem>
        <listitem>
          <simpara>
            [Benchmark] Scalar fusion is a significant opportunity for performance increase and is the primary
            bottleneck in Dyalog APL interpretation based strategies
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Benchmark] Many optimization transformation conducted by hand on Dyalog code had to do with copy avoidance
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Benchmark] Avoiding garbage collection and providing predictable allocation behavior is a win
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Benchmark] Cache behavior is one of the key performance killers in the existing system, and a core target for
            optimization in the compiler
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Benchmark] A specialized runtime can keep up with other code in most cases when the above conditions are
            not affecting the performance.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Specification] Tokenization scheme is suggested by the abstract stimuli chosen
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Specification] Recursions inherent in the problem are indicated by the recursive stimuli
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Specification] Recursive stimuli suggest a decomposition and grammar for the AST
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Specification] Many stimuli lend themselves to aggregate analysis
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Specification] Variables and their relation to primitives is very complex and should be handled carefully in the AST
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Specification] The AST should allow for easy analysis of primitive values, whatever they are named
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Specification] Atom-level elements of the AST are suggested by the stimuli sets and scheme in general
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Specification] Function expressions are the most state-heavy elements due to the number of classes of operator behavior and the supporting of nested behavior
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            [Language Reference] The Language Reference should be used to provide detailed behavior of the primitives and the
            nature of promotion
          </simpara>
        </listitem>
      </itemizedlist>
      <section>
        <title>Analysis: Nanopass</title>
        <simpara>
          The NanoPass compiler framework is a Scheme eDSL designed to make it easier to write 
          compilers by using a series of small compiler passes over a series of ASTs that are 
          all related to one another. A compiler pass in the NanoPass framework consists of 
          an input and output grammar for the language being transformed, and the code that 
          described the transformation from the old grammar into the new grammar. 
        </simpara>
        <simpara>
          Andy Keep demonstrated in his dissertation that the NanoPass framework scaled to 
          commercial compiler enterprises effectively. However, the framework itself does not 
          fit with the requirement to have a self-hosting compiler. The overall approach can be 
          kept the same, and indeed, the NanoPass style is probably best for lifting out the 
          salient features of the compiler and making the compiler easier to modify and to 
          understand. 
        </simpara>
        <simpara>
          Adapting the NanoPass framework to Co-Dfns will require a few changes. Namely, it is 
          slightly more difficult to do careful checking of error conditions on grammars, which 
          the NanoPass framework gives by default. This will require either explicit checking 
          or adaptation in terms of the grammars used. One approach would be to use a single
          unified grammar rather than many smaller grammars, and then make adjustments based on 
          this. This has the benefits of making the definition of the AST simpler, and could 
          simplify some of the code, but will require the use of more rigorous development 
          processes to offset potential problems with verification of the output of each 
          pass.
        </simpara>
        <simpara>
          The NanoPass framework also encourages a pure functional, compositional approach to 
          pass development, and this is a very good practice. Thus, state should, in general, not 
          be shared across passes, and the overall design of the compiler should be as state-free 
          as can be managed. Mutation, if used, should be isolated to a single scope and depth for 
          any given mutation over any given object. Global state may be used, but should remain 
          fixed for any given run of the compiler and should not change from one pass to the next.
        </simpara>
        <simpara>
          A final insight from the NanoPass framework is the benefit of thinking in terms of a series 
          of global transformations over an object, rather than on local iterations over the same 
          space. We can scale this even further to encourage programming in the aggregate as much as 
          possible for clarity. This means that we should avoid as much as possible iterations and 
          recursions that cannot be expressed as a simple aggregate transformation. Where recursion is 
          inherent in the problem, then it makes sense to use recursion where expected but otherwise, 
          we should hope to avoid the use of unnecessary control structures where aggregate operations 
          can more succinctly express the problem. This has benefits both in terms of potential 
          performance and in terms of problem decomposition. This decomposition is the primary concern 
          of our state-box design methodology that we use to replace the traditional box-structure 
          method of doing state-box design.
        </simpara>
        <itemizedlist spacing="compact">
          <title>Summary of NanoPass Insights</title>
          <listitem>
            <simpara>Compiler should use a single unified grammar</simpara>
          </listitem>
          <listitem>
            <simpara>Use a formal verification of the correctness of each compiler pass</simpara>
          </listitem>
          <listitem>
            <simpara>Use small, numerous compiler passes rather than large, monolithic passes</simpara>
          </listitem>
          <listitem>
            <simpara>Use aggregate, pure-functional programming as much as possible</simpara>
          </listitem>
          <listitem>
            <simpara>Global state is okay, but should remain immutable throughout a given compiler invocation</simpara>
          </listitem>
        </itemizedlist>
      </section>
      <section>
        <title>Analysis: LLVM</title>
      </section>
      <section>
        <title>Analysis: Parsing Prototypes</title>
        <simpara>
          Three main parsing prototypes have been created, each using a different parsing technology. 
          These were implemented in three different languages: C, C++, and Dyalog. The C version used the Peg(1) 
          parser generator, while the C++ version used the Boost Spirit parser combinators. The Dyalog version 
          was an attempt to move the parser generator style based on combinators into the Dyalog framework. 
        </simpara>
        <simpara>
          The peg(1) based parsers all suffered from a single major flaw: difficulty in threading state information 
          up and down the channels of parsing. In other words, the Co-Dfns language has a few places where ambiguity 
          exist and require information about the bindings in the environment to disambiguate. In particular, it is 
          important to know whether a variable is bound to a value, a function, or a monadic or dyadic operator, and 
          if it is some sort of operator, what operator it is. 
        </simpara>
        <simpara>
          The interpreter gets around this by leaving some of this ambiguity around until runtime, but it also 
          interleaves evaluation with parsing, so that parsing already has some environmental information ahead of 
          time. The compiler will not have this luxury. Instead, it seems necessary to have a series of passes specifically 
          for the parser to enable it to extract the important information ahead of time without requiring all of 
          the elements to be parsed. 
        </simpara>
        <simpara>
          The Boost C++ parser was the most successful attempt, and the boost system does in fact have facilities for 
          parsing while threading information through the system. It became clear, however, that the clarity of the 
          code was beginning to suffer through the system, and the approach still resulted in the need to have a multi-phase 
          parser that would have looked slightly convoluted in the Spirit combinators, despite their capacity.
        </simpara>
        <simpara>
          The vast majority of parsing in Co-Dfns is very simple, or at least, regular in description. It is possible to 
          use state machines to describe most of the behavior of the system (see the analysis of 
          <citetitle>Function Specification</citetitle>) with only very specific instances of needing recursion. This leads 
          to the general conclusion that a traditional in-code parser written using aggregate operators on top of a decent 
          tokenization will lead to better results and a more readable solution, allowing the code to match very closely the 
          regular and recursive elements and keeping the code much more compact than would have arisen with the use of a 
          parser library.
        </simpara>
        <simpara>
          Even if most of the instances of ambiguity are removed through the use of a multi-stage parser, there are specific 
          instances in the case of operators with the <literal>⍺⍺</literal> and <literal>⍵⍵</literal> types and the 
          ambivalent assignment of <literal>⍺</literal> that result in ambiguities which cannot be easily removed. Thus, 
          the grammar will need to be able to take into account different compilation strategies for different versions.
          Fortunately, the potential differences are isolated and contained within a single scope and do not extend across 
          scopes.
        </simpara>
        <itemizedlist spacing="compact">
          <title>Summary of Parsing Prototypes Insights</title>
          <listitem>
            <simpara>Most of the parsing of Co-Dfns is regular</simpara>
          </listitem>
          <listitem>
            <simpara>There are specific cases of necessary recursions</simpara>
          </listitem>
          <listitem>
            <simpara>There are simple, but necessary needs for muli-pass refinements of the parsing</simpara>
          </listitem>
          <listitem>
            <simpara>The parser must use passes to extract type information for variables in order to eliminate most ambiguity</simpara>
          </listitem>
          <listitem>
            <simpara>Some instance of ambiguity will remain</simpara>
          </listitem>
          <listitem>
            <simpara>The grammar will need to take into account those instances of ambiguity that cannot be eliminated</simpara>
          </listitem>
          <listitem>
            <simpara>Most of the parser should be able to use aggregate style programming to express the parsing stages clearly</simpara>
          </listitem>
        </itemizedlist>
      </section>
      <section>
        <title>Analysis: Runtime Prototypes</title>
        <simpara>
          There were two runtimes created, one in C and one in Java. Comparing their behavior to existing 
          systems and to each other, it is clear that runtimes written in either of these languages will 
          create some limitations for the compiler. In particular, benchmarking reveals that fusion will 
          be a major factor, as will good cache behavior. However, the runtimes created in either of these 
          languages, if they encompass many of the primitives, will not be able to easily leverage 
          cache or fusion optimizations in the compiler, and will operate more or less independently of 
          one another. 
        </simpara>
        <simpara>
          The general conclusion to this is that the runtime should be mostly written in Co-Dfns itself. 
          However, there is a trade-off in compilation complexity. When most of the runtime is in the 
          C or Java side, it is possible for us to avoid the need to destruct arrays. We can keep them 
          as opaque things and not worry about what is inside them during compilation. If elements of the 
          compiler are lifted out of that, then it will be necessary for us to handle the internals of 
          arrays directly in the compiler. However, having a small runtime that handles certain things 
          for us directly, without requiring additional work, will make it easier to do the compiler 
          things, without introducing significant overhead issues. Thus, a minimal runtime environment 
          will be helpful, but most of the primitives should be implemented in Co-Dfns.
        </simpara>
        <simpara>
          Comparing the C and Java prototypes, Java has some clear advantages, but also some serious 
          disadvantages. Since the target of the system is in fact the LLVM system, C has much better 
          integration with the system, and has better opportunities to leverage existing libraries 
          for multi-programming to scale things into the large and especially distributed computing.
          C also allows for better control over the calling conventions, which may improve the ability 
          to do fast execution with minimal hackery.
        </simpara>
        <simpara>
          An additional interesting issue related to the semantics of the runtime system is the 
          promotion semantics. In Dyalog, a given value might be promoted to another class if its value 
          exceeds a certain amount. This would include going from an integer to a floating point number when 
          the number exceeds the bounds of the integer size. The runtime needs to provide a good facility 
          for handling these sorts of promotions in a way that is fast. 
        </simpara>
        <simpara>
          The handling of scalar operations is interesting in light of the desire to implement fusioning.
          Given the nature of promotion mentioned above, scalar operations could have a potentially complex 
          internal element to them, while additionally having the opportunity for better cache behavior 
          if the scalar operations can be fused into a single loop. This fusing should be accomplished through 
          the compiler, but that still leaves to question the behavior of the individual scalar operations. 
          These are potentially good targets to have in the runtime, provided that the compiler mitigates the 
          cost of a function call to these individual operations.
        </simpara>
        <simpara>
          Ideally speaking, despite the requirement that we might have to be able to get to the internals 
          of the array structure, it is beneficial if we an avoid worrying about the internals of the array 
          structure as much as possible in the compiler. Thus, it might make sense to have runtime helpers 
          that will destruct and manage the array structure in an efficient way without requiring the 
          compiler to have explicit knowledge of the data structures used for the arrays. If the compiler is 
          unaware of the underlying structure, it can make it easier to make some changes without affecting 
          the compiler directly. This needs to be balanced with the ability of the compiler to make interesting 
          optimizations happen.
        </simpara>
        <itemizedlist spacing="compact">
          <title>Summary of Runtime Prototype Insights</title>
          <listitem>
            <simpara>Runtime should provide facilities for array class promotion</simpara>
          </listitem>
          <listitem>
            <simpara>It might make sense to have individual scalar operations in C</simpara>
          </listitem>
          <listitem>
            <simpara>Scalar functions are probably best implemented in Co-Dfns</simpara>
          </listitem>
          <listitem>
            <simpara>Most of the primitive functions and operators should be implemented in Co-Dfns, not in the runtime</simpara>
          </listitem>
          <listitem>
            <simpara>Implementation language of the core runtime should be C</simpara>
          </listitem>
          <listitem>
            <simpara>Runtime should take cache behavior into account</simpara>
          </listitem>
          <listitem>
            <simpara>The compiler should try to mitigate the cost of a function call</simpara>
          </listitem>
        </itemizedlist>
      </section>
      <section>
        <title>Analysis: Performance Benchmarks</title>
        <simpara>
          A series of benchmarks, mostly taken from the NAS Parallel Benchmarks suite were implemented in Dyalog APL.
          These were compared against the reference versions in Fortran and C provided by the NPB. Analysis of these 
          benchmarks verified some initial expectations of the compiler, but also revealed that certain issues would 
          not be relevant. 
        </simpara>
        <simpara>
          In particular, the benchmarks revealed that cache behavior played a very significant role in the relative 
          performance of the two systems. Where the cache behavior of Dyalog was not friendly, then we saw 10 times or 
          worse slow downs compared to the reference implementations. However, where this was not an issue, the Dyalog 
          system could keep up with the reference implementations nearly tit for tat, though in some versions it was 
          around 2 or 3 times slower. 
        </simpara>
        <simpara>
          The use of specific, optimized runtime elements gets good results in many cases, but the case of strings 
          of scalar functions on large arrays is a clear bottleneck for the Dyalog interpreter which likely cannot 
          be easily handled using just the interpreter technology without significant effort. Additionally, memory 
          usage is a concern, and garbage collection can present some limitations. Thus, it is beneficial if the 
          language can be implemented without the need for garbage collection and in a predictable, allocation 
          friendly way. There are man opportunities for optimization in these cases. 
        </simpara>
        <simpara>
          Finally, significant optimization focused transformations needed to be applied to the simpler Dyalog code 
          in order to get it to go fastest, including some optimizations which were not obvious or that obfuscated 
          the code somewhat. Many of these optimizations were for the sake of memory allocation or copying costs. 
          The compiler, then, has a great opportunity to improve this behavior by using a cost-effective strategy 
          for allocation and avoding copying if it can, while still keeping the code simple, and not requiring 
          excessive massaging to get the code into a copy-friendly state.
        </simpara>
        <itemizedlist spacing="compact">
          <title>Summary of Benchmarking Insights</title>
          <listitem>
            <simpara>
              Scalar fusion is a significant opportunity for performance increase and is the primary 
              bottleneck in Dyalog APL interpretation based strategies
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Many optimization transformation conducted by hand on Dyalog code had to do with copy avoidance
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Avoiding garbage collection and providing predictable allocation behavior is a win
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Cache behavior is one of the key performance killers in the existing system, and a core target for 
              optimization in the compiler
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              A specialized runtime can keep up with other code in most cases when the above conditions are 
              not affecting the performance.
            </simpara>
          </listitem>
        </itemizedlist>
      </section>
      <section>
        <title>Analysis: Function Specification</title>
        <simpara>
          The <citetitle>Function Specification</citetitle> is a work product of our development process and 
          includes the detailed specification of the compiler behavior as an external Black Box definition.
          A number of interesting elements came out of this effort.
        </simpara>
        <simpara>
          The first advantage is a clear identification of the sort of tokens that matter most and their 
          classifications. These are mostly abstract, but serve as an useful initial guide for the tokenization 
          effort as well as for the definition of the Grammar.
          Secondly, the specification divides the complexity of the system into four classes of entities in the 
          system, which informs the grammar. Furthermore, these classes identify the only places where recursion 
          is inherent in the problem.
          Examining the specification, many of the stimuli lend themselves to aggregate 
          examination and processing without requiring iteration through the tokens.
        </simpara>
        <simpara>
          Variables are one of the most complex stimuli in the specification, as expected, since they can hold 
          so many different values. It will be helpful to link the variable and primitive functions in such a 
          way that one can identity all of the instances of a primitive, regardless of its name. Additionally, 
          the grammar should make sure to clearly identify the class or type of a variable. 
        </simpara>
        <simpara>
          Each of the classes of recursive stimuli which partition the various values also suggests an implementation 
          strategy for the various sub-classes of these recursions. In particular, it suggests that we should 
          attribute the various types to the stimuli in the expression to ensure that we can handle them either as a 
          group or specifically. It also suggests that we can create the grammar at least partially from the core 
          stimuli and then the recursive stimuli, which will not be atomic.
          The stimuli are abstract enough to suggest a possible atom-level vocabulary for the grammar and AST of 
          the compiler.
        </simpara>
        <simpara>
          The specification quite unexpectedly reveals that the most complex component of the parser and likely of the 
          system in general, at least in terms of state-space, is the function expressions, and not anything else. 
          In fact, there is a huge difference in terms of the state-space of the function expressions as compared to 
          anything else. Further analysis reveals that the reason for this massive explosion of state compared to the
          other systems is the different classifications and results of the various operators, together with the 
          requisite handling of these operators under the presence of parentheses. Handling these nested cases results 
          in a significant amount of complexity to ensure that parentheses don't get in the way, and map accurately 
          to the concepts contained by them.
        </simpara>
        <itemizedlist spacing="compact">
          <title>Summary of Function Specification Insights</title>
          <listitem>
            <simpara>
              Tokenization scheme is suggested by the abstract stimuli chosen
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Recursions inherent in the problem are indicated by the recursive stimuli
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Recursive stimuli suggest a decomposition and grammar for the AST
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Many stimuli lend themselves to aggregate analysis
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Variables and their relation to primitives is very complex and should be handled carefully in the AST
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              The AST should allow for easy analysis of primitive values, whatever they are named
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Atom-level elements of the AST are suggested by the stimuli sets and scheme in general
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Function expressions are the most state-heavy elements due to the number of classes of operator behavior and the supporting of nested behavior
            </simpara>
          </listitem>
        </itemizedlist>
      </section>
      <section>
        <title>Analysis: Language Reference</title>
        <simpara>
          In general, most of the information that can be gleaned from the Language Reference is embedded in the 
          <citetitle>Function Specification</citetitle> or some other element, including the prototypes. However, 
          the language reference remains the only place to get a clear view of the semantics of each individual 
          primitive, and it generally does a good job of defining this behavior. It also is the place to locate 
          the information about how promotion works in detail, which is outside of the scope of detail in 
          the <citetitle>Function Specification</citetitle>. While little can be extracted from the reference, 
          it should be used as the means to define the behaviors of some of the more detailed elements of the 
          runtime system when that time comes.
        </simpara>
        <itemizedlist spacing="compact">
          <title>Summary of Language Reference Insights</title>
          <listitem>
            <simpara>
              The Language Reference should be used to provide detailed behavior of the primitives and the 
              nature of promotion
            </simpara>
          </listitem>
        </itemizedlist>
      </section>
      <section>
        <title>Analysis: Miscellaneous Observations</title>
      </section>
    </section>
    <section>
      <title>Software Strategy</title>
    </section>
    <section>
      <title>Top-level Structure</title>
      <section>
        <title>AST Definition</title>
      </section>
      <section>
        <title>Pass Overview</title>
      </section>
      <section>
        <title>Pass Specifications</title>
      </section>
    </section>
  </section>
</article>