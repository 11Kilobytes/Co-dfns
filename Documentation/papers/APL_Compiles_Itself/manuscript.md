# AbstractQuick, how do you write a compiler without branching, conditionals, case statements, or recursion?The Co-dfns compiler transforms a parallel extension of the dfns dialect of APL into C and CUDA code.  It targets the GPU as well as the CPU.  It also pushes the assumptions of viable application domains for array programming. In particular, Co-dfns is implemented in the Co-dfns language.  Furthermore, an explicit design aesthetic of the compiler style requires that, whenever possible, all compiler passes have no conditionals, branching, or recursion in their descriptions.  Surprisingly, not only can this be done, but the resulting compiler exhibits both consision and simplicity.Nearly the entire compiler, including the handling of lexical scope, function lifting, and closure creation, contains no explicit branching, traditional control structures, or recursion: each compiler pass contains a simple data flow implementation with almost trivial control flow.  Using traditional array programming concepts together with insights into how to encode control flow information into simple data representations, The Co-dfns compiler demonstrates a novel and interesting approach to compiler implementation.# IntroductionModern compiler design relies on recursion and branching execution. Clang's `RecursiveASTVisitor` implements a recursive traversal combined with methods for node operations, essentially a case statement. The Nanopass compiler framework supports compilers as the composition of many small tree transformations defined by dispatching on node type and recuring on children either implicitly or explicitly. This reliance should surprise none: the patterns of control flow exhibited by recursion and branching match very naturally the essence of compiler implementation, tree traversal. What if you could not use branching or recursion?Likely, few would even make the attempt to create a compiler that used neither recursion nor branching. Indeed, what value lives in such an artifact? Such an artifact would certainly challenge and elucidate the construction of compilers in ways not previously seen. Moreover, today's modern architectures exhibit features which suggest that such an approach could also benefit the practical implementation of compilers. Particularly, modern CPU's have vector engines; GPU's generally prove difficult targets for which to implement a traditional compiler; and, distributed systems benefit from more parallel implementations. A vectorized compiler that uses data-parallel operations and simple, straightforward control flow instead of recursion and branching provides insights into tree traversal and avenues for research into the efficiency of compilers and similar programs on modern computing architectures. The Co-dfns compiler transforms a parallel extension of the dfns dialect of APL into C and Cuda code. Uniquely, the implementation is written entirely in Co-dfns. While Co-dfns readily supports recursion and branching, the project pushes the scale and range of APL by implementing the compiler using the native APL vocabulary and traditional array-programming idioms, rather than using recursion or branching. This leads to a very lean, concise, and simple compiler that exhibits very different characteristics both aesthetically and operationally.Modulo parsing, the entire Co-dfns compiler uses the APL array language vocabulary and a nanopass style composition of small, pure functional compiler passes, written with simple data-flow control, to convert between the Co-dfns language, whose AST is encoded as an array, into the target language, a mix of C and Cuda for execution on both the CPU and GPU. The compiler will also target HPX for execution of parallel code on SMP and distributed clusters.The following sections discuss the key implementation insights for each of the major front-end compiler passes for languages that exhibit similiar features to Co-dfns, including lexical scope and higher-order functions. For each pass, the key implementation insight and overall strategy of compilation demonstrates the methods and algorithms used to arrive at a fully vectorizable compiler suitable for execution on the GPU. The exposition of these passes also reveals the concision and compactness of the approach, which accounts for the small amount of code necessary to implement the compiler. Readers may observe the external artifacts and references for the entire compiler source.# Notational Conventions# Language DefinitionThe compiled language consists of a simplified intermediate AST representing a program as might reasonably appear just before function lifting and flattening passes might occur. In particular, no function body contains any literal values, and expressions are semi-flattened. An attribute table attaches to each node in the AST, in addition to children that might appear. In this sense, the AST matches very closely the model used by XML trees. The AST described in [AST table] gives each node along with its set of attributes and its children.    Module[] := (FuncExpr | Expression)*    FuncExpr[name] := Function | Variable    Function[] := Expression*    Expression[name;class] := [Variable] FuncExpr Expression | Variable    Variable[name] := ()All ASTs start with a single `Module` node as their sole root node. `FuncExpr` nodes encapsulate function objects either by reference or by their definition. Functions consist of expressions. Note that `Function` nodes model the same sort of functions described in the previous section on notation. That is, they bind one or two arguments implicitly, and receive a single right argument and a single, optional left argument. Expressions here differ from traditional expressions in that they are already partially flattened. This treatment of expressions omits the compiler pass to partially flatten expressions to this pattern for simplicity of exposition. Expressions either refer to a variable binding or one of two sorts of function application. The `class` attribute of the Expression indicates the expression type, either a variable reference, a monadic application of a function, or a dyadic application. The `FuncExpr` and `Expression` nodes may contain a `name` attribute, indicating a binding for that particular object. In addition to the explicit restrictions on the AST, the compiler passes described here presume that another compiler pass has already removed any unnamed (and therefore, useless) top-level expressions as well as syntactically unreachable code within the function bodies. # Compiler PassesIn order to perform flattening and lifting, the following series of compiler passes suffice to move from an AST as described above to a flattened AST, described in [Flattened AST table].    Module[] := (FuncExpr | Expression)*    FuncExpr[name] := Function | Variable    Function[] := Expression*    Expression[name;class;left;right;fn;        left_env;env;slot;left_slot;right_env;right_slot] := ()    Variable[name] := ()In particular, all function bindings now occur at the top-level, and all function bodies consist of expressions with no children. Instead, each expression contains attributes for the left and right arguments as well as the function name. Additionally to the name, for each reference there are two additional attributes, giving the environment index and slot position for that variable's location. The environment indicates how far up in the lexical stack to reach, and the slot gives the appropriate position in that environment that contains the variable referenced. The passes to achieve this lifting and flattening are listed in [Pass Table].    rn ← Record node coordinates    rd ← Record scope depths    lf ← Lift functions to top-level    fe ← Flatten Expressions    av ← Anchor variables## Node Coordinates## Scope Depths# Function Lifting# Expression Flattening## Variable Anchoring# ConclusionBy focusing on the use of linearizing passes and by lifting important structural information out of the control flow of the program and into the structure of the data itself, the Co-dfns compiler makes progressive, simple passes that massage the code into its final form, suitable for generation to the target language. This simplicity also results in very compact implementations for each compiler pass, as the mathematically oriented array notations such as APL provide a direct and natural language for these solutions. This concision comes in part because some of the information that might have been explicitly encoded into the control flow of the program instead lives in the AST, which, of course, does not affect the source code of the program directly. The Co-dfns compiler demonstrates not only that a branchless, recursion-free, and vector-friendly compiler can be written, but that such a compiler, while very different, does not require obscure encodings of the same algorithms, instead sitting in its own right with unique algorithms that approach the problem from a different perspective. This presents opportunities both from a pedagogical and practical standpoint. It is not clear that this new perspective will result in faster compilers on GPUs or distributed machines, but at the very least it presents an interesting avenue of research into compiler design and implementation, which results in very compact and concise code  that demonstrates just how generally useful the array oriented programming model could be.