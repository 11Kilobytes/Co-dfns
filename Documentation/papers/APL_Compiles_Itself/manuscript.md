# No branching, no recursion, no problem: Lexical scoping with arrays# AbstractQuick, how do you write a compiler without branching, conditionals, case statements, or recursion?This programming pearl describes a direct, straightforward method of lifting functions and resolving lexical scope using only well known array operations without any branching, conditionals, or recursion. It uses established executable array notation so that all formal descriptions are executable and can be tried and used to explore these concepts further. It suggests how this approach allows for the further development of array-oriented designs for compiler construction. # IntroductionEveryone learns to think about compilers using recursion and branching control flow. How would a compiler look without either? Many modern architectures such as GPUs incur a high cost for thread divergence and tend to perform well on dense array calculations. Ask computer scientists, "How do you write a compiler without branching, conditionals, or recursion?" They might look at you suspiciously. If they know modern programming languages, which include higher-order functions and lexical scope as a matter of course, they may follow that question with, "Wait, how do you lift functions and resolve lexically scoped variables?"Unlike other graph algorithms, which never modify the structure of the graph, compilers primarily alter the code graph. This makes them interesting and challenging to understand in the native "vocabulary" of vector oriented machines like GPUs. Most solutions focus heavily on algorithmic performance, taking careful thought as to the data representation and the implementation of primitive operations [citations]. This does little to elucidate the comprehension of compiler passes in terms more suited to the GPU or other vector machines. This pearl describes function lifting and variable resolution, that is, identifying into which scope and position in that scope a given variable belongs, in the language of arrays. Using well known array operations over n-dimensional rectangular arrays, the given compiler passes transform a nested, lexically scoped language into a flat representation where all functions appear at the top-level and all variable bindings explicity receive a specific environment and position. The exposition relies only on executable array notation, focusing on how the exploration of arrays suggests solutions to this problem. The end result: a crisp, concise solution to function lifting and variable anchoring that requires no recursion, no branching, no conditionals. It presents a clear demonstration of array-oriented thinking on compiler transformations, as well as the sort of data encodings required to make such reasoning direct. This is part of an effort to implement a high-performance, self-hosting array language compiler, Co-dfns.## Contributions* A simple, direct, straightforward approach to function lifting and variable anchoring using only standard array operations* A definition of these operations in a readily available executable notation suitable for exploration and pedagogy [citation]* An exposition of these techniques that suggests how further exploration of these algorithms might progress and how to explore the space of array programming to arrive at solutions to compiler transformations which might otherwise appear too difficult to implement# Notational ConventionsAll the algorithms use a subset of APL's array notation to describe the executable expressions that implement each compiler pass, suitable for execution for execution on Dyalog APL 14.0 or greater. All expressions evaluate from right to left with equal precedence order for all functions. Functions appear infix and take a right argument with an optional left argument. Functions that return other functions, called operators, take a left operand and possibly a right operand. Operators associate to the left instead of the right, as normal expressions do. Finally, all operations occur over n-dimensional rectangular arrays. The representation of these arrays as dense or sparse does not matter here. Functions and operators taking two arguments or operands are called dyadic, while those taking only one are called monadic. Tables [...] give the summary of functions and operators used, as well as a quick guide to notation. Table of Functions:         Dyadic                                            Monadic    +   Addition                                          N/A    ⌈   Max                                               N/A    ,   Catenate                                          Vector of elements in row-major order (ravel)    ⍳   Find first occurence                              Index Generate    =   Numeric equality                                  N/A    ↑   Take left elements from right                     Mix    ⊂   N/A                                               Enclose argument to form nested scalar array    ∧   Boolean AND                                       N/A    ∨   Boolean OR                                        N/A    ⊢   Right argument                                    Identity    ⍉   N/A                                               Transpose    ⌽   N/A                                               Reverse    ∩   Intersection                                      N/A    ⍴   N/A                                               Shape (Vector of dimensions of the array)    ⊤   Encode vector index to array index based on shape N/A    ⊥   Inverse of Encode, decode array index to vector indexTable of Operators:    f/A         Reduce along last axis of `A` with function `f`    f⌿A         Reduce along first axis of `A` with function `f`    f⍀A         Scan along first axis of `A` with function `f`    A f.g B     Compute inner product of `f` and `g` over `A` and `B`    A ∘.f B     Compute the outer product of `f` over `A` and `B`    K f⌸ A      Apply `f` for each unique major cell in `K` with all associated cells in `A`    A f⍤i j⊢B   Compute `f` for each cell of rank `i` in `A` with cell of rank `j` in `B`    A f∘g B     Compose `f` with `g`, thus `A f∘g B ←→ A f (g B)`Table of Syntax:    f g h   Functions    A B C   Arrays    m n o   Operators        A (f g h) B ←→ (A f B) g (A h B)    A (g h) B   ←→ g (A h B)    B (A f g) C ←→ A f (B g C)    A f B g C   ←→ A f (B g C)    f m n g     ←→ (f m) n g    f m n o     ←→ ((f m) n) o     A ← ...    Give A the value of ...The concept of cells helps to explain how operators apply functions along arrays. Specifically, a major cell is a sub-array of an array whose shape is that of the shape of the array less the first dimension. Thus, the major cells of a matrix are its rows. The rank 1 cells of a 3-dimensional array are the rows of each sub-matrix described by the array. The rank 2 cell of a matrix is just the matrix itself. In this treatment, scalar values are just rank 0 arrays. Finally, some expressions use the convention known as function trains. The basic equivalencies enable a concise expression of a series of applications and may be familiar from other mathematical domains. In the following equivalencies, `f`, `g`, and `h` are functions, and `a`, `b`, and `c` are array values:    a (f g h) b ←→ (a f b) g (a h b)    b (a g h) c ←→ a g (b h c)    a (f g) c   ←→ f (a g c)# Language DefinitionThe compiled language consists of a simplified intermediate AST representing a program as might reasonably appear just before function lifting and flattening passes might occur. In particular, no function body contains any literal values. An attribute table attaches to each node in the AST, in addition to children that might appear. In this sense, the AST matches very closely the model used by XML trees. The AST described in [AST table] gives each node along with its set of attributes and its children.    Module[]               := (FuncExpr | Expression)*    FuncExpr[name]         := Function | Variable    Function[]             := Expression*    Expression[name;class] := [Expression] FuncExpr Expression | Variable    Variable[name]         := ()All ASTs start with a single `Module` node as their sole root node. `FuncExpr` nodes encapsulate function objects either by reference or by definition. Functions contain expressions. Note that `Function` nodes model the same sort of functions described in the previous section on notation. That is, they bind one or two arguments implicitly and receive a single right argument and a single, optional left argument. Expressions either refer to a variable binding or one of two sorts of function application. The `class` attribute of the `Expression` indicates the expression type, either a variable reference, a monadic application of a function, or a dyadic application. The `FuncExpr` and `Expression` nodes may contain a `name` attribute, indicating a binding for that particular object. In addition to the explicit restrictions on the AST, the compiler passes described here presume that another compiler pass has already removed any unnamed (and therefore, useless) top-level expressions as well as syntactically unreachable code within the function bodies.## Encoding the ASTBecause all the compiler passes operate over arrays, the AST must exist in some array encoding of the tree structure, in this case, a 3-column matrix. Each row corresponds to a single node in the AST, ordered by pre-order depth-first traversal. The first column contains the depth of that node in the AST, starting with 0 for the root node. The second column contains the name of the node. The third column contains a 2-column association matrix associating a given key/attribute, with the value for that attribute. This representation encodes all relevant information, but also has the added benefit of being a standard tree encoding used within the APL programming community.  # Compiler PassesIn order to perform flattening and lifting, the following series of compiler passes suffice to move from an AST as described above to a flattened AST, described in [Flattened AST table].    Module[]       := (FuncExpr | Expression)*    FuncExpr[name] := Function | Variable    Function[]     := Expression*    Variable[name] := ()    Expression[name;class;left;right;fn;        left_env;env;slot;left_slot;right_env;right_slot] := ()In particular, all function bindings now occur at the top-level, and all function bodies contain expressions with no children. Instead, each expression contains attributes for the left and right arguments as well as the function name. Additionally to the name, for each reference there are two additional attributes, giving the environment index and slot position for that variable's location. The environment indicates how far up in the lexical stack to reach, and the slot gives the appropriate position in that environment that contains the variable referenced. For simplicity this section omits expression flattening, since the techniques match those of function lifting.## Node CoordinatesTraditional implementations of lifting and flattening encode information about the structure of the AST through recursion and branching on node types. Any method of lifting and flattening must encode this information in some usable way. Instead of using recursion and control flow to encode this structural information, consider the depth vector `d` of the AST. This vector encodes all of the structural information required to understand the parent-child relationships of the AST. Unfortunately, it does so in a way that does not allow for local reasoning about any two nodes in the tree without surrounding context. Before function lifting, a compiler pass re-encodes this information such that the structural relationship of any two nodes exists locally for each node, requiring no external context. In particular, given the reference or coordinate for any two nodes, simple array operations suffice to determine whether one node is an ancestor of the other, the depth of each node in relation to the other, and whether one node appears before or after the tree in the traversal. This information will prove critically important in other passes, so the pass annotates each node with an additional `ref` attribute containing the node reference, also called a coordinate. A node coordinate is a vector of length equal to the depth of the AST, consisting of natural numbers, whose non-zero elements precede its zero elements, the count of which equal the depth of the node. Additionally, a node is an ancestor of another node if and only if its coordinate is a prefix of the second node's coordinate, ignoring zeros. A coordinate corresponds to a path from the root of the tree to the node. A coordinate also represents a unique identifier for any given node as an index into a multi-dimensional array whose rank is the depth of the AST. To compute the matrix of all coordinates, consider first the set of natural numbers from zero to the depth of the AST, inclusive, given by the following expression:    ⍳1+⌈/0,dHere `d` is the depth vector of the AST. Now consider the boolean matrix given by the outer product equating each element of the range and each element of the original depth vector, given by the following expression:    d∘.= ⍳1+⌈/0,dThe result depicts a neat little pictorial representation of the information encoded in the depth vector, using more space. In particular, the tree like structure becomes obvious. Let `d` be given the following value:    d←<Some suitable code here>The structure defined by this tree becomes more clear by the above outer product:          d∘.= ⍳1+⌈/0,d    <Insert Example Here>The above picture suggests another way of encoding the same information by scanning along the first dimension, resulting in the prefix sum for each column of the matrix. The following expression demonstrates this result using the same depth vector:          +⍀d∘.=⍳1+⌈/0,d    <More data here>Now, each row has a unique value encoding an index, and nearly all the desired invariants exist in the above matrix. However, spurious non-zero values exist which do not contribute to the uniqueness of the coordinates and likewise provide no further useful information. These spurious values are any non-zero values that appear in columns past the depth of any given node. By taking only the number of non-zero values up to the depth of each node, the appropriate coordinate matrix emerges.       r←(1+d)↑⍤¯1+⍀d∘.=⍳1+⌈/0,d    <More data here>Given this coordinate matrix, named `r`, all the other compiler passes may now compute with the parent-child relationships without requiring recursion or branching.## Function LiftingFunction lifting involves three particular insights to complete. Firstly, note that by computing the dimensions of the space described by the coordinate matrix, that is, the range of each column in the matrix, given by the maximum value plus one for each column, any given node may be given a unique natural number as an identifier. The following expression computes this dimension information, called `rm`:    rm←1+⌈⌿rHere `r` represents the coordinate matrix. Given `rm` and any row of `r`, a unique natural number identifier for that node is given by `rm⊥⍺` where `⍺` is a row of `r`. Each node stores this information locally, so each lifted `Function` node already provides a unique variable with which to replace it in the tree. This allows all variable generation to occur without requiring an accumulator or some other stateful system, which might require non-local computation.Next, some general strategy must exist for doing the actual lifting. In this case, the answer comes from a surprising place. Assume that a function `ngh` takes a coordinate as its left argument and a matrix group of nodes as its right. In this case the coordinate is the coordinate of the function directly enclosing the nodes given on the right. The group of nodes in the right argument is the body of the function, including all `Function` nodes appearing in the body of the function, but *without* their bodies. In this case, the `ngh` function has all the information necessary to create the lifted function definition at the top level. It need only replace each `Function` node, which no longer has children, with a `Variable` node using the unique identifier derived from the coordinate given in the `ref` attribute of the node, manipulate the depth vector of the group to shift all nodes to the top-level depth, preserving order and internal relationships, and finally, add a new function definition node enclosing the function group, using the given coordinate it received as its left argument. Note the importance of reusing the coordinate after lifting. The coordinate information must preserve the original structural information of the code, even after compiler passes mostly remove this structure from the AST.Now assume that there exists a value `c` which contains the coordinate for each node of the tree that corresponds to the `Function` to which that node belongs. This `c` matrix contains the grouping information for each function body, in the form of a set of keys by which to group each node. At this point, all of the information is in place to do function lifting, if only a strategy for lifting existed. In a stroke of surprising invention, the array programming community possesses just such a strategy. The Key (written `⌸`) operator existed as an array programming primitive since at least the J programming language [citation] and the Connection Machine [citation]. Given an array representation of keys on the left and a set of corresponding elements on the right, it applies its left operand once for each unique key in the left argument, passing the unique key as the left argument to the operand, and the set of elements associated with that key as the right argument. Here is a simple example:          2 1 3 2 3 ,∘⊂⌸ ⍳5    ┌─┬───┐    │2│0 3│    ├─┼───┤    │1│1  │    ├─┼───┤    │3│2 4│    └─┴───┘Importantly, the key operator preserves the order both of the appearance of the keys as well as the appearance of the elements. By applying this key operator to the set of scope keys given by `c` and the operand `ngh`, the result is a re-ordered tree with each scope given its own top-level function definition. This also has the side-effect of lifting all top-level expressions into a single group, which turns out to be useful in future passes. Thus, given `c` and `ngh`, the following expression lifts all functions to the top level.    c ngh⌸ ⍵Here `⍵` is the body of the `Module`. How does one compute `c`? Firstly, compute the value `sc`, which is all the scope coordinates with their last non-zero element zeroed. Secondly, compute `rf`, the coordinate matrix of all scope nodes, namely `Module` and `Function`. Then, the following expression computes the boolean matrix indicating which elements of `rf` are prefixes or equal to each row in `sc` by using an inner product:          sc∧.(=∨0=⊢)⍉rf    <Insert data here>The function `(=∨0=⊢)` is a predicate indicating whether the right argument is a prefix or equal to the left argument. This is combined with boolean `∧` in an inner product given by `∧.(=∨0=⊢)` to compute the boolean matrix. At this point, note that if one constructs lexicographically ordered `sc` and `rf` values, then the last true value in each row of the resulting matrix indicates the closest enclosing scope for each node. From this information the `c` matrix can be constructed naturally. For simplicity, this treatment omits the definition of `ngh`, as it is a natural function that requires only simple manipulation in an obvious and direct way to achieve its results.The above technique using the Key operator for flattening also works when applied to flatten expressions which have a nested structure.## Variable AnchoringVariable anchoring converts variables references or assignments into a pair of natural numbers, indicating the environment in which to find that variable, as well as the "slot" or position in which that variable occurs within the environment. This removes any environment lookups for all subsequent passes in the compiler. At the point where variable anchoring occurs, the AST already exhibits a mostly flat structure, with all functions at the top level and all expressions flattened out to a linear form. Again, a handler for each scope or function body may operate independently of each other scope through the use of the key operator. Note that it is not necessary to use the node coordinates for grouping at this point, as the depth vector provides sufficient information to group using a simple sum scan. The handler does require two structures for its operation. The `sk` matrix gives the node coordinates for each scope node, indicating the total set of all possible environments in the module. The `sb` matrix gives the bindings for each of these scopes. Each row in `sb` contains a set of the unique names bound in the scope identified by the corresponding row in `sk`. Taking `r` to be the coordinate of the currently processed scope, the prefixes of `r` which appear in `sk` determines the relevant rows out of `sb` that may contribute to the bindings in this scope, given by the following expression:          ⌽1+⍳r⍳0    <Insert data here>          sk⍳((⌽1+⍳r⍳0)↑⍤0 1⊢r)∩sk    <Insert data here>These rows form the `b` matrix for the current scope, which is used to find the slots and environments for each name appearing in the given scope, given by `nm`. This can be done quite easily because an index into `b` pointing to any given variable is the same as the environment and slot for that variable. Thus, it suffices to find the index of each variable relative to `b`, which the following expression accomplishes through the use of the find (`⍳`) function and the encode (`⊤`) function.          (⍴b)⊤(,b)⍳nm    <Insert data here>Note here that some additional care must be used depending on how the scoping in a given language works. For example, a variable could be bound in one scope, but may be bound later in the function body, such that references to the same variable before the binding actually refer to a binding in a containing environment. The techniques described above still apply, but require some additional book-keeping to ensure that incorrect bindings do not occur. # Related WorkThe J programming language [citation] was one of the first practical, general-purpose programming languages to introduce the key operator as a primitive operator with the presumption of its general usefulness. The rank operator (`⍤`) used throughout this treatment also derives from the J traditional, receiving particular interest throughout the APL community [citation]. The EigenCFA effort [citation] demonstrated significant performance improvements of a 0-CFA flow analysis by utilizing similar techniques to those demonstrated here. In particular, encoding the AST and using accessor functions have a very similar feel to the node coordinates and AST encoding given here, though they have a different formulation and spend considerable effort understanding the trade-offs of performance associated with the different encodings, whereas the encodings here were chosen for their clarity and directness, rather than their performance. Mendez-Lojo, et al. implemented a GPU version of Inclusion-based Points-to Analysis [citation] that also focuses on adapting data structures and algorithms to efficiently execute on the GPU. In particular, they use similar techniques of prefix sums and sorts to achieve some of their adaptation to the GPU, Additionally, they have clever and efficient methods of representing graphs on the GPU which enable dynamic rewriting of the graph. Earlier work on APL compilers [APEX, Budd] developed vectorized versions of certain parts of an APL compiler, but the APL language at the time had no lexically scoped variation, and as such used a simpler dynamic scoping rule which did not require the same sort of analysis, as no nested functions could be syntactically constructed. # Future WorkA small compiler for a lexically scoped dialect of APL (Co-dfns) currently utilizes these approaches to implement the lexical features of the language. It targets Cuda and C for further compilation. All the given code above elucidates the concepts as directly as possible, without significant consideration to the target upon which they will execute. The efficient execution of the above expressions on vector-oriented architectures such as GPUs, or large distributed machines, will require consideration of the array representations such as whether to use dense or sparse matrices (evidence suggests sparse matrices are a clear win [citation]). Additionally, efficient implementations for operators such as inner product and key must exist for the target platforms. Further exploration of the compiler design will determine whether these techniques scale to other problems, such complicated optimizations. Prior research indicates that techniques such as these do in fact enable efficient implementation on GPUs [citation], but requires more study of different algorithms and optimizations, as well as a more complex language than that presented here. The above techniques suggest that a self-hosted APL compiler that efficiently executes on the GPU does not exceed the realm of reasonable expectation. Significant work still remains to accomplish such a goal, however.# ConclusionGiven a few key insights into encoding a tree into an AST and representing relationships between nodes in a suitable manner, one can implement lexical scoping semantics for a given language using nothing but well known array operations, without complex control flow, recursion, or branching. The rank, scan, key, inner and outer product operators form the backbone of such computation, suggesting that efficient implementation of these primitives may enable a completely self-hosted array language compiler to exist on the GPU in the future.# AcknowledgmentsThis work is graciously funded by Dyalog, Ltd. to support the construction of a high-performance APL compiler.