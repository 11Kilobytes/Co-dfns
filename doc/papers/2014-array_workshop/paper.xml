<?xml version="1.0" encoding="utf-8" ?>

<article xmlns="http://docbook.org/ns/docbook" version="5.0">
  <info>
    <title>Co-dfns: Ancient Language, Modern Compiler</title>
    <authorgroup>
      <author>
        <personname>Aaron W. Hsu</personname>
        <affiliation><orgname>Indiana University</orgname></affiliation>
        <email>awhsu@indiana.edu</email>
      </author>
    </authorgroup>
    <date>Thursday, March 13th, 2014</date>
    <abstract>
      <para>
        The APL language allows subject matter experts with no 
        computer science experience to create large and complex 
        software implementations of ideas without excessive 
        costs for software engineering and external development.
        The rapid increase in data sizes challenges existing 
        APL systems, which are all interpreters, to scale with 
        the domain expert's problem size. The Co-dfns project, 
        currently in early development stages, focuses on 
        delivering new language innovations and a high-performance 
        compiler for modern APL that enables domain experts to scale 
        their ideas to the size of the problems as well as the 
        massive parallelism in modern hardware architectures.
        The Co-dfns language provides concise primitives that 
        allow domain experts to utilize concurrency and explicit 
        task parallelism in their code. The compiler addresses
        critical performance bottlenecks of the Dyalog APL interpreter,
        while maintaining strong integration and compatibility with existing 
        APL workflows, Co-dfns will allow domain experts to scale 
        their code more successfully without requiring them to 
        rewrite critical portions of their code in other languages. 
        Early benchmarking efforts indicate that even naive and 
        unoptimized versions of the Co-dfns compiler compete well 
        with Dyalog APL on code that naturally lends itself to APL.
      </para>
    </abstract>
  </info>
  <section>
    <title>Introduction</title>
    <para>
      The general purpose array languages, especially APL, represent a 
      critical business tool for a set of domain experts. These experts 
      often rely on APL to construct large software systems oriented around 
      their particular expertise. Unlike traditional computer scientists, 
      or software engineers, the domain expert primarily intends to solve 
      a problem outside of computation; the agility and low-cost that APL 
      provides, primarily by reducing the domain expert's dependence on 
      external engineering resources. This low-overhead, direct engagement 
      with the programming environment distinguishes APL's primary successes 
      from language such as C++ or C. 
    </para>
    <para>
      The systems developed in this manner could be small, but often scale 
      to very large sizes. This includes treasury management, risk 
      and portfolio management, oil refining optimization, and large 
      installations of patient journals and health data. Increasingly, 
      in the fields where APL thrives, such as health data, finance, and 
      large simulations, the sizes of the data continues to grow rapidly. 
    </para>
    <para>
      This rapid increase of data size combines with the large scale of 
      the software systems to challenge the current APL systems. The success 
      of these systems hinges on the ability of the APL system to provide a 
      clear environment for domain experts to solve the problem themselves, 
      but the increasing size of data strains the current APL implementations. 
      As the size of data increases, it becomes increasingly important that 
      domain experts can work with these large data sizes without requiring 
      hand optimization or reimplementation of their models into other 
      languages to obtain desirable performance. That is, their workflow 
      should not suffer because of the size of the data. 
    </para>
    <para>
      Unfortunately, most APL implementation use interpreters. This makes 
      sense from a historical standpoint, and APL interpreters deliver impressive 
      performance, in part because APL programs often rely on primitives 
      and idioms that the intrepeter optimizes. This approach cannot scale to 
      the large, multi-core, multi-node, multi-device computational 
      hierarchies in modern machines. For instance, consider the following 
      computation, which comes from a Black Scholes formula for 
      predicting options pricing.
    </para>
    <programlisting>D1←((⍟S÷X)+(r+(v*2)÷2)×T)÷vsqrtT</programlisting>
    <para>
      This will likely go very fast on small data sizes. The scalar 
      primitives operating over the variables can 
      leverage highly tuned libraries and vectorization. Unfortunately, 
      the interpreter must run these primitives in order, and thus, 
      as the array sizes grow, the cache locality disintegrates, 
      and the APL interpreter will experience signification reductions 
      in performance compared to hand-written C code. The problem 
      gets worse when attempting to target the GPU or distributed clusters, 
      as current APL systems do not have any story there.
      The Co-dfns project addresses these performance issues from two 
      directions, the language itself, and the implementation. 
    </para>
    <para>
      The Dyalog APL interpreter already uses threading to improve 
      performance of primitive operations. Users have little control 
      over this behavior however, and more often, good parallelism 
      requires explicit consideration at the algorithmic level. Thus, 
      the Co-dfns language extends the traditional SIMD parallelism 
      and multi-threaded runtime features of APL with carefully designed 
      primitives for explicit task parallelism and synchronization. 
      These integrations allow users to use concurrency explicitly. 
      Their design allows domain experts to easily write deterministic 
      parallel programs. Section 3 describes these language innovations 
      in detail.
    </para>
    <para>
      The Co-dfns implementation compiles APL code rather than interpreting 
      it, using LLVM as a backend. The compiler is written in Co-dfns 
      itself and integrates directly with the Dyalog APL interpreter, 
      allowing users to access and use compiled code without ever leaving 
      the interactive APL session. Though still in the early stages of 
      development, the design of the compiler and the optimizations 
      target the most significant bottlenecks in the interpreter, namely, 
      memory management and function fusion. It takes a high-level approach 
      to optimization, and relies on LLVM to deliver the appropriate 
      low-level support. The compiler means to replace the need for 
      users to rewrite critical regions of their code in Cuda or C to 
      scale the performance to acceptable levels as the data sizes 
      increase. As such, the compiler design focuses on creating scalable 
      code, both across devices and hardware as well as size of data.
      Section 4 describes the Co-dfns compiler.
    </para>
    <para>
      Though still immature as a compiler, some useful benchmarks and 
      performance results exist. Section 5 describes these. 
    </para>
  </section>
  <section>
    <title>Background</title>
    <para>
      APL first appeared in 1957 in <citetitle>A Programming Language</citetitle>
      by Kenneth Iverson, who designed the language as an unambiguous 
      mathematical notation for teaching and research. This mathematical 
      and concise nature of the language make it attractive for certain 
      fields and experts. The first implementations of APL, however, 
      favored interactivity and dynamic behavior, using dynamic scoping 
      and mostly flat workspaces of functions. The use of goto statements, 
      execute functions, and dynamic scoping made it difficult to implement 
      full APL compilers. 
      In 1996, John Scholes introduced dfns, which provided a lexically scoped, 
      functionally oriented notation for writing APL code. This notation 
      eliminates many of the barriers to fast compilation. See Figure YYY 
      for a summary of the APL notation used in the following sections.
    </para>
    <para>
      The LLVM project provides a complete low-level compiler that transforms 
      the LLVM intermediate representation (IR) into native code. It targets 
      multiple architectures, including PTX (for GPU programming), and 
      x86_64 code. It provides many useful low-level optimizations that often 
      require significant effort to implement. This includes function inlining 
      and loop vectorization. It also provides a MCJIT system which enables 
      just-in-time compilation of code in-memory, which suits the needs of 
      the Co-dfns compiler particularly well.
    </para>
    <para>
      When spawning a new parallel computation, in functional languages, 
      often the result of that computation goes into a future. The future 
      serves as a placeholder for the data until the parallel computation 
      completes. Attempting to read the future blocks until the data associated 
      with that future exists. An IVar, or immutable variable, holds at 
      most a single value in its lifetime. When created, it holds no value, 
      and future computations may write at most once into that value. Attempting 
      to read the contents of the variable will block until some computation 
      writes to the variable. Futures and ivars often serve as the 
      synchronizing data structure in deterministic computation for functional 
      programming.
    </para>
  </section>
  <table frame="void">
    <title>APL Syntax Summary</title>
    <thead>
      <tr>
        <th>Expression</th>
        <th colspan="2">Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><literal>f A</literal></td>
        <td colspan="2">Apply <varname>f</varname> to <varname>A</varname>.</td>
      </tr>
      <tr>
        <td><literal>A f B</literal></td>
        <td colspan="2">
          Apply <varname>f</varname> to <varname>A</varname>
          and <varname>B</varname>.
        </td>
      </tr>
      <tr>
        <td><literal>V←Expr</literal></td>
        <td colspan="2">
          Give <literal>Expr</literal> the name <varname>V</varname>.
        </td>
      </tr>
      <tr>
        <td><literal>A[B]</literal></td>
        <td colspan="2">
          Extract array of same shape as <varname>B</varname> from 
          <varname>A</varname> by using each element in <varname>B</varname>
          as an index into <varname>A</varname>.
        </td>
      </tr>
      <tr>
        <td><literal>S1 ⋄ S2</literal></td>
        <td colspan="2">
          Evaluate <literal>S1</literal> and then <literal>S2</literal>.
        </td>
      </tr>
      <tr>
        <td><literal>{ ... }</literal></td>
        <td colspan="2">
          Function definition
        </td>
      </tr>
      <tr>
        <td><varname>⍺</varname></td>
        <td colspan="2">
          The left formal argument in a function definition.
        </td>
      </tr>
      <tr>
        <td><varname>⍵</varname></td>
        <td colspan="2">
          The right formal argument in a function definition.
        </td>
      </tr>
      <tr>
        <td><literal>T:E</literal></td>
        <td colspan="2">
          Inside a function, if <literal>T</literal> then return 
          <literal>E</literal>.
        </td>
      </tr>
      <tr>
        <td><literal>f¨A</literal></td>
        <td colspan="2">
          Apply <varname>f</varname> to each element in <varname>A</varname>.
        </td>
      </tr>
    </tbody>
  </table>
  <section>
    <title>Language Innovations</title>
    <para>
      The dfns language tells a fine story for spiritually functional
      data parallel programming; the bulk simd parallelism of
      APL forms the language foundation, not a veneer over mostly 
      serial programs. It does not, however, allow the natural 
      expression of task parallelism. Normal APL operations map well 
      to vector engines, but not to OS threads and concurrent programming. 
    </para>
    <para>
      Traditional solutions to task parallelism in APL bolted on
      concurrency constructs such as mutexes and
      guards, with APL underneath. This approach suffers from the
      same programmability problems that these same constructs have
      in any language, while additionally imposing a significant
      cost on language concision and productivity for
      domain experts. Such constructs serve domain experts little,
      even if the expert might otherwise benefit from a concurrent 
      paradigm. It also unnecessarily complicates the life of a 
      tuning expert.
      Deterministic parallelism somewhat relieves these
      issues by eliminating by construction some undesirable 
      non-determinism in parallel programs. The traditional expression 
      of these features, however, does not map any more nicely to 
      APL than mutexes, guards, or the like.
    </para>
    <para>
      Task parallelism in APL ought to satisfy two criteria: 
      it should feel like APL, and it should be easy to use safely.
      That is, these constructs should not destroy
      APL's concise expression, nor greatly burden domain experts to use.
      Co-dfns extends the basic dfns language to enable
      both non-deterministic and deterministic task parallelism
      without requiring any additional syntax, and introducing only
      two new primitives to the language.
    </para>
    <para>
      Firstly, a new literal <literal>⌾</literal> (target) represents the
      new datatype, a single assignment array. A single assignment
      array works like other arrays except that a slot in the array
      receives at most one value in its lifetime. The <literal>⌾</literal>
      value behaves like the empty vector literal <literal>⍬</literal>,
      except that its fill value is a single assignment slot.
      The reshape <literal>S⍴⌾</literal> builds
      a single assignment array of shape <varname>S</varname>, where 
      <varname>S</varname> gives the dimensions of the array. This
      array begins empty, and each slot may be assigned a value at most once. 
    </para>
    <programlisting>A←2 2⍴⌾  ⍝ SA matrix of shape 2 2
A[0;0]←1 ⍝ Assign 0 0 slot to 1
A[0;0]←5 ⍝ Error, multiple writes</programlisting>
    <para>
      Attempting to read a slot in a single assignment array blocks until 
      that slot receives a value. In this way, single assignment arrays 
      deliver IVars in a fashion that completing integrates them with 
      normal APL: they feel like any other normal array during use. 
    </para>
    <para>
      Co-dfns provides concurrent execution through an operator
      <literal>∥</literal>. The expression <literal>F∥</literal> is
      equivalent to the function <varname>F</varname> but when applied 
      returns immediately with a single assignment array whose values 
      will contain the results of executing F concurrently with the rest 
      of the program. Assuming <varname>F</varname> does not deadlock, 
      the array returned is equivalent to the array that would have been 
      returned by the function called without <literal>∥</literal> 
      assuming no error conditions.
    </para>
    <programlisting>pfib←{ ⍝ Parallel Fibonacci
  1=⍵:1
  2=⍵:1
  (pfib∥⍵-1)+(pfib∥⍵-2)
}</programlisting>
    <para>
      These two primitives suffice to deliver task parallel computation 
      in the dfns APL dialect. Single assignment arrays allow for 
      synchronization, while the parallel operator enables concurrency. 
      This approach requires no explicit control constructs or syntax.
      These primitives present an attractive alternative to
      traditional approaches because of the implicit and concise expression 
      of concurrency and synchronization. Moreover, by restricting all 
      inter-thread arrays (arrays touched by more than one thread) to single 
      assignment arrays, these constructs also exhibit determinism.
    </para>
  </section>
  <section>
    <title>Implementation</title>
    <para>
      The language of Co-dfns explicitly tries to make concurrency a tool 
      of thought for domain expert programming. The implementation of 
      Co-dfns also has explicit goals:
    </para>
    <orderedlist spacing="compact">
      <listitem>
        <para>
          Enable APL programs to scale to larger problems and modern 
          hardware, including massively parallel systems.
        </para>
      </listitem>
      <listitem>
        <para>
          Make it easy to integrate the compiler into existing APL 
          workflows.
        </para>
      </listitem>
      <listitem>
        <para>
          Support integration with external tools through well documented 
          interfaces and easy to use entry and exit points.
        </para>
      </listitem>
      <listitem>
        <para>
          Support compiled APL that seamlessly integrates with external 
          software products and systems.
        </para>
      </listitem>
    </orderedlist>
    <para>
      Since this is an early stage project, the compiler does not realize 
      all of these goals to a great degree. The current compiler addresses 
      these through four primary designs.
    </para>
    <formalpara>
      <title>Memory management</title>
      <para>
        Systems like Dyalog APL use a garbage collector to manage memory. 
        Garbage collectors liberate programming implementations and languages 
        greatly, and serves as the de facto standard memory management model 
        for most all new languages. This is good. In Co-dfns, however, 
        because the language design enforces a natural stack lifetime on 
        variables and functions, the compiler uses a stack discipline to 
        implement all memory management, completely avoiding the extra 
        complexity and cost of integrating a high-performance garbage collector 
        into the runtime. 
      </para>
    </formalpara>
    <para>
      Interestingly, this decision does not preclude the use of operators, 
      which are higher-order functions in APL which return functions. Functions 
      cannot escape out of a lexical context, which would require indefinitely 
      lifetimes of function values. These stack functions permit a wide range of 
      higher-order programming, but require no closure allocation. Indeed, all 
      Co-dfns functions map directly to an LLVM function. Thus, the compiler 
      takes advantage of LLVM optimizations which might otherwise prove more 
      difficult or costly to implement directly, such as inlining. 
    </para>
    <formalpara>
      <title>Fusion</title>
      <para>
        Existing research into parallel system demonstrates the importance and 
        effectiveness of good fusion over certain operators. The Dyalog interpreter 
        performance suffers even in cases where it might due well, because it 
        cannot fuse scalar primitive functions together to leverage modern 
        memory hierarchies. Full scalar function fusion does not yet exist in 
        the Co-dfns compiler, but the use of stack functions above enables the 
        inlining of many other explicit functions, including primtives. Further 
        increments of the compiler development will introduce scalar function 
        fusion.
      </para>
    </formalpara>
    <formalpara>
      <title>Modularity and Integration</title>
      <para>
        The Co-dfns compiler tries as much as possible to avoid needless reinvention 
        of proven techniques or code. It uses the LLVM compiler to provide a 
        stable and mature compiler backend, with many optimizations. It uses a 
        variety of the Nanopass compiler design philosophy, in which many small 
        compiler passes, functional and stateless, compose together to form a complete 
        transformation from the input language to the output language. 
        Furthermore, each compiler pass accepts as input and output a data format 
        which trivially serializes to XML. Thus, at any given point in the compiler, 
        the state of the compiler easily exports into a portable lexical format. 
      </para>
    </formalpara>
    <para>
      The above design choices result in a compiler that easily integrates into 
      external tools. The use of LLVM and choice of memory management strategies 
      also gives very standard, compatible object files produced by the compiler. 
      These compiler products can be linked into existing applications without 
      any real change in the compilation toolchain. For Dyalog APL users, this 
      means that the results of the compiler fit directly into the rest of the 
      compiler with a generic wrapper around each compiled function. Work continues 
      to eliminate any manual part of this, using the LLVM MCJIT system to 
      allow Dyalog to completely integrate the compiler without any extra manual 
      effort on the part of Dyalog users, greatly lowering the barrier to entry 
      into using the compiler. 
    </para>
  </section>
  <figure>
    <title>Black Scholes Benchmark Code</title>
    <programlisting>r←0.02 ⋄ v←0.03 ⋄ p←÷(○2)*0.5

CNDP←{
  K←÷1+0.2316419×L←|⍵
  R←p×(*(L×L)÷¯2)×{coeff+.×⍵*1+⍳5}¨K
  (1 ¯1)[B]×((0 ¯1)[B←⍵≥0])+R
}

BlackScholes←{
  expRT←*(-r)×T ⋄ vsqrtT←v×T*0.5
  D1←((⍟S÷X)+(r+(v*2)÷2)×T)÷vsqrtT
  D2←D1-vsqrtT
  CD1←CNDP D1 ⋄ CD2←CNDP D2
  R←(S×CD1)-X×expRT×CD2
  R,[0.5]((X×expRT×1-CD2)-S×1-CD1)
}</programlisting>
  </figure>
  <section>
    <title>Evaluation</title>
    <para>
      The Co-dfns compiler does not yet support the entire language, and it 
      does not currently implement many of the intended optimizations designed 
      for it. This makes evaluation challenging, as most benchmarks leverage 
      a fairly wide array of language features and primitives. Notwithstanding
      these challenges, the Co-dfns compiler can compile the Espen Haug 
      Black Scholes calculation. 
    </para>
    <formalpara>
      <title>Blackscholes benchmark</title>
      <para>
        The black scholes formula estimates options pricing, and the 
        implementation of black scholes favors APL Interpreters to a fair 
        degree. Particularly, it requires very little code, and an APL 
        implementation contains very little structural control flow, 
        reducing the interpreter overhead. Moreover, the benchmark deals 
        mostly with scalar calculations over large arrays, for which 
        APL can implement specialized primitives that perform very well.
      </para>
    </formalpara>
    <para>
      The benchmark does a good job of measuring the performance of APL 
      on number crunching applications heavy with scalar computation. It 
      also benefits from good memory and cache locality as the size of 
      the data set increases. 
    </para>
    <formalpara>
      <title>Benchmarking Methodology</title>
      <para>
        To compare the Co-dfns compiler and Dyalog APL, the benchmarking 
        harness simulates as much as possible the intended use case of 
        the compiler. That is, execution of the compiled code should 
        occur as transparently as possible from within the Dyalog APL 
        system, and should not require excessive tooling. 
      </para>
    </formalpara>
    <para>
      The current state of the compiler limits to some degree the level 
      of attainable integration. In particular, the benchmark was 
      compiled offline and linked together as a shared object, rather 
      than taking advantage of LLVM's MCJIT system. Additionally, a 
      custom wrapper function handled the conversion of interpreter 
      data structures to and from the compiler structures, calling out 
      to the shared object to perform the actual computation. This simulates 
      the work that the JIT would do, but it still forms an undesirable 
      manual step in the benchmarking process. 
      The compiled objects were compiled using clang 3.4 with O3 optimizations, 
      but no other explicit optimization settings. 
    </para>
    <para>
      Each version of the benchmark, one for the interpreter and one for the 
      compiler, used the same APL implementation of the black scholes, though 
      the code used for the compiler was cosmetically tweaked to work around 
      some limitations in the current implementation of the compiler. 
      Each version ran on each data set size three times, and the average 
      of these three computations was taken. Each run performed a collector 
      compaction before running the code. 
    </para>
    <para>
      The testing machine used an Intel Core i7-3610QM CPU @ 2.30Ghz with 
      16GB of RAM with Dyalog APL 14.0 Beta 3 on Red Hat Enterprise Linux 
      7.0 Beta. 
    </para>
    <formalpara>
      <title>Results</title>
      <para>
        See the figures for two versions of the same results, one on a 
        logarithmic scale and the other without any logarithmic adjustment. 
        The logarithmic scale demonstrates the performance characteristics 
        of the smaller sizes, while the linear scale demonstrates the 
        proportions of performance factors at large sizes better. 
      </para>
    </formalpara>
    <para>
      Note that the interpreter outperforms the naive, partial implementation 
      of the compiler at low data sizes, but then begins to suffer performance 
      degredation as the size increases. The compiler begins to outperform 
      the interpreter, increasingly so as the sizes of the data grows. 
      The compiler outperforms the interpreter by 26% at the largest data set, 
      without performing any specific optimizations available to it. 
    </para>
    <para>
      The performance of the compiler at the low-end likely indicates the 
      inefficiency of the current approach to injecting and projecting data 
      to and from the compiled code, as this would most significantly influence 
      the results at the low-end. Moreover, the interpreters handling of locality 
      likely contributes to the failure to scale linearly as the data increases. 
      The compiler does a better job of this right now, but could undoubtedly 
      improve a great deal through the use of fusion optimizations. 
    </para>
  </section>
  <figure pgwide="1">
    <title>Black Scholes Benchmark Results</title>
    <inlinemediaobject>
      <imageobject>
        <imagedata align="center" width="3.5in" 
                   fileref="linear.svg" format="SVG" />
      </imageobject>
    </inlinemediaobject>
    <inlinemediaobject>
      <imageobject>
        <imagedata align="center" width="3.5in"
                   fileref="logarithmic.svg" format="SVG" />
      </imageobject>
    </inlinemediaobject>
  </figure>
  <section>
    <title>Related Work</title>
    <para>
      Froma theoretical standpoint, Lenore Mullin's dissertation on the
      Mathematics of Arrays provides a foundation upon which much of the
      compiler optimizations are based, in terms of reasoning about the shapes
      of arrays and their overall values. Heretofore, this work has not been
      incorporated into the compiler, but in the future it will serve as the
      basis for a number of planned compiler passes.
    </para>
    <para>
      Timothy Budd implemented an APL compiler for a traditional APL system
      that he describes in <quote>An APL Compiler</quote>. The work presents
      a unique and interesting approach to reducing computation on arrays
      by lazily executing computations. Budd's compiler delayed computation
      until the point at which the program requested the value. As in most
      traditional APL compilers, the language of the compiler does not match
      directly with the semantics of normal APL programs of the time. Budd's
      compiler also managed allocation without requiring a garbage collector.
    </para>
    <para>
      Bob Bernecky implemented the APEX compiler, which perhaps best represents
      the traditional APL compiler. It has useful passes, such as data flow
      analysis and static single assignment. Moreover, Bernecky details an
      approach at introducing parallelism into the compiler itself. While the
      APEX compiler is not self-hosting, the efforts to introduce a parallel
      expression of the compiler passes should inform the design of the Co-dfns
      passes and their design. The APEX compiler does suffer from a strong
      number of restrictions, some of which could evaporate given enough
      programmer effort. Both the APEX and Co-dfns compilers share some
      restrictions, such as not allowing the dynamic fixing of new functions
      at runtime. However, much more effort is made to ensure that existing
      dfns programs in Dyalog will run without modification in the Co-dfns compiler
      than the similar compatibility in the APEX compiler.
    </para>
    <para>
      Dyalog has provided a good deal of input into the Co-dfns compiler, and
      so it makes sense that the upcoming release of their interpreter begins
      to implement some of the ideas embedded into the Co-dfns compiler. This
      includes a facility for doing coarse-grained parallelism with futures,
      but does not include any ability to do more refined concurrent operations
      since the interpreter lacks single assignment arrays for synchronization;
      the system itself makes not guarantees when effects occur in parallel.
    </para>
    <para>
      A number of systems such as Manticore, ZPL, and Accelerate are able to
      provide interesting implementation strategies for array programming,
      each emphasizing different elements. They all take the overall approach
      of altering the language design in favor of making certain features
      prevalent. Accelerate, for instance, lifts rank to the type level,
      meaning that shapes are no longer first class entities. ZPL uses a
      more traditional language but enables predictable data layout for distributed
      computing. Manticore takes advantage of the language and implemenation to
      make heavy use of fusion and fision.
    </para>
    <para>
      Eric Holk's Harlan system takes a unique approach. Targeting the GPU
      explicitly, it tries to introduce traditional programming concepts as
      native concepts on the GPU, so that traditional programs can run reasonably
      on the GPU. This approach, instead of lifting array programming to the
      general-purpose sphere, pulls general-purpose language constructs such as
      ADTs into the GPU and array world through the use of region inference and
      a number of other transformations. It also uses the NanoPass style of
      compiler design and includes a macro system on top of it to reduce the
      number of core forms for the compiler to deal with.
    </para>
  </section>
  <section>
    <title>Moving Forward</title>
    <para>
      Much work still remains to bring the compiler to its firt public version. 
      This includes implementing more optimizations centered around 
      memory management, fusion, and targeting the GPU as well as the CPU. 
      Eventually, the compiler should also host itself, as it is written in 
      dfns. Among the optimizations that have the highest priority are the 
      work of ... to reduce copying of arrays, minimizing allocations and maximizing 
      reuse of memory, and integrating richer and more native scalar function 
      fusion into the compiler. 
    </para>
    <para>
      Further work continues on exploring irregular problem domains, such as
      the compiler itself, and graph algorithms, such as the Graph500 Benchmark. 
      Getting good results on these problems requires additional effort into 
      memory management, such as recognizing shape and types of the array 
      values and doing preallocation of the memory regions before computation. 
      On benchmarks like the Graph500 this can save copying overhead in
      tight loops and make GPU performance much better.
    </para>
  </section>
  <section>
    <title>Conclusion</title>
    <para>
      The Co-dfns compiler, despit the early stages of its development, shows 
      promise for bringing robust scalability to the venerable APL language 
      in the context of modern hardware and platforms, on increasingly large 
      data sets. Unlike many efforts in the array field, the Co-dfns compiler 
      intends from the beginning to be accessible to the domain expert, 
      rather than targeting the computer scientist, and to exhibit suitable 
      industrial strengths for mature applications. The current stage of 
      development can only say so much regarding the future capacity of the 
      compiler, but it does demonstrate the feasibility of the approach and 
      a reasonable expectation of suitable performance gains.
    </para>
  </section>
  <section>
    <title>Acknowledgments</title>
    <para>
      Bob Bernecky provided excellent insight into the state of APL
      compilation. Dyalog, Ltd. has provided gracious funding for the
      development of this compiler. Ryan Newton and Andrew Lumsdaine 
      have greatly aided in directing this research. 
    </para>
  </section>
  <appendix>
    <title>Demo description</title>
    <para>
      Description of the demo of the tool.
    </para>
  </appendix>
  <appendix>
    <title>APL Primitives</title>
    <para>
      A simple cheat sheet for what all the APL primitives do.
    </para>
  </appendix>
</article>
