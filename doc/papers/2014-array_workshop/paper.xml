<?xml version="1.0" encoding="utf-8" ?>

<article xmlns="http://docbook.org/ns/docbook" version="5.0">
  <info>
    <title>Co-dfns: Ancient Language, Modern Compiler</title>
    <authorgroup>
      <author>
        <personname>Aaron W. Hsu</personname>
        <affiliation><orgname>Indiana University</orgname></affiliation>
        <email>awhsu@indiana.edu</email>
      </author>
    </authorgroup>
    <date>Thursday, March 13th, 2014</date>
    <abstract>
      <para>
        The APL language allows subject matter experts with no 
        computer science experience to create large and complex 
        software implementations of ideas without excessive 
        costs for software engineering and external development.
        The rapid increase in data sizes challenges existing 
        APL systems, which are all interpreters, to scale with 
        the domain expert's problem size. The Co-dfns project, 
        currently in early development stages, focuses on 
        delivering new language innovations and a high-performance 
        compiler for modern APL that enables domain experts to scale 
        their ideas to the size of the problems as well as the 
        massive parallelism in modern hardware architectures.
        The Co-dfns language provides concise primitives that 
        allow domain experts to utilize concurrency and explicit 
        task parallelism in their code. The compiler addresses
        critical performance bottlenecks of the Dyalog APL interpreter,
        while maintaining strong integration and compatibility with existing 
        APL workflows, Co-dfns will allow domain experts to scale 
        their code more successfully without requiring them to 
        rewrite critical portions of their code in other languages. 
        Early benchmarking efforts indicate that even naive and 
        unoptimized versions of the Co-dfns compiler compete well 
        with Dyalog APL on code that naturally lends itself to APL.
      </para>
    </abstract>
  </info>
  <section>
    <title>Introduction</title>
    <para>
      The general purpose array languages, especially APL, represent a 
      critical business tool for a set of domain experts. These experts 
      often rely on APL to construct large software systems oriented around 
      their particular expertise. Unlike traditional computer scientists, 
      or software engineers, the domain expert primarily intends to solve 
      a problem outside of computation; APL provides agility and low-cost
      by reducing the domain expert's dependence on 
      external engineering resources. This low-overhead, direct engagement 
      with the programming environment distinguishes APL's primary successes 
      from language such as C++ or C. 
    </para>
    <para>
      The systems developed in this manner could be small, but often scale 
      to very large sizes. This includes treasury management, risk 
      and portfolio management, oil refining optimization, and large 
      installations of patient journals and health data. Increasingly, 
      in the fields where APL thrives, such as health data, finance, and 
      large simulations, the sizes of the data continues to grow rapidly. 
      The size of these problems often exceeds the ability of even large 
      machines to store all relevant information in RAM, or even on a single 
      machine. 
    </para>
    <para>
      This rapid increase of data size combines with the large scale of 
      the software systems to challenge the current APL systems. The success 
      of these systems hinges on the ability of the APL system to provide a 
      clear environment for domain experts to solve the problem themselves, 
      but the increasing size of data strains the current APL implementations. 
      As the size of data increases, it becomes increasingly important that 
      domain experts can work with these large data sizes without requiring 
      hand optimization or reimplementation of their models into other 
      languages to obtain desirable performance. That is, their workflow 
      should not suffer because of the size of the data. 
    </para>
    <para>
      Unfortunately, most APL implementations use interpreters. This makes 
      sense from a historical standpoint, and APL interpreters deliver impressive 
      performance, in part because APL programs often rely on primitives 
      and idioms that the intrepeter optimizes. This approach cannot scale to 
      the large, multi-core, multi-node, multi-device computational 
      hierarchies in modern machines. For instance, consider the following 
      computation, which comes from a Black Scholes formula for 
      predicting options pricing.
    </para>
    <programlisting>D1←((⍟S÷X)+(r+(v*2)÷2)×T)÷vsqrtT</programlisting>
    <para>
      This will likely go very fast on small data sizes. The scalar 
      primitives operating over the variables can 
      leverage highly tuned libraries and vectorization. Unfortunately, 
      the interpreter must run these primitives in order, and thus, 
      as the array sizes grow, the cache locality disintegrates, 
      and the APL interpreter will experience signification reductions 
      in performance compared to hand-written C code. The problem 
      gets worse when attempting to target the GPU or distributed clusters, 
      as current APL systems do not have any story there.
      The Co-dfns project addresses these performance issues from two 
      directions, the language itself, and the implementation. 
    </para>
    <para>
      The Dyalog APL interpreter already uses threading to improve 
      performance of primitive operations. Users have little control 
      over this behavior however, and more often, good parallelism 
      requires explicit consideration at the algorithmic level. Thus, 
      the Co-dfns language extends the traditional SIMD parallelism 
      and multi-threaded runtime features of APL with carefully designed 
      primitives for explicit task parallelism and synchronization. 
      These integrations allow users to use concurrency explicitly. 
      Their design allows domain experts to easily write deterministic 
      parallel programs. Section 3 describes these language innovations 
      in detail.
    </para>
    <para>
      The Co-dfns implementation uses a unique compiler architecture,
      which combines the nanopass philosophy of compiler design with the
      dfns language. The compiler is a single Dyalog APL namespace
      implemented in dfns APL as a pure functional composition of
      compiler passes. Though in the early stages of development, the
      current design solves all the major issues of APL compilation
      without using a garbage collector or closures, despite the
      higher-order style of programming that Co-dfns allows. The
      architecture allows the compiler to take full advantage of
      existing LLVM optimizations, and lays the groundwork for future
      high-level optimizations including function fusion and memory
      layout/locality optimizations, two of the primary performance
      bottlenecks in Dyalog APL. Users can compile APL code
      interactively without ever needing to leave their APL sessions.
      The compiler means to replace the need for users to rewrite
      critical regions of their code in Cuda or C to scale the
      performance to acceptable levels as the data sizes increase. As
      such, the compiler design focuses on creating scalable code, both
      across devices and hardware as well as size of data. Section 4
      describes the Co-dfns compiler.
    </para>
    <para>
      Though still immature as a compiler, some useful benchmarks and 
      performance results exist. Section 5 describes these. 
    </para>
  </section>
  <section>
    <title>Background</title>
    <para>
      APL first appeared in 1957 in <citetitle>A Programming Language</citetitle>
      by Kenneth Iverson, who designed the language as an unambiguous 
      mathematical notation for teaching and research. This mathematical 
      and concise nature of the language make it attractive for certain 
      fields and experts. The first implementations of APL, however, 
      favored interactivity and dynamic behavior, using dynamic scoping 
      and mostly flat workspaces of functions. The use of goto statements, 
      execute functions, and dynamic scoping made it difficult to implement 
      full APL compilers. 
      In 1996, John Scholes introduced dfns, which provided a lexically scoped, 
      functionally oriented notation for writing APL code. This notation 
      eliminates many of the barriers to fast compilation. See Figure YYY 
      for a summary of the APL notation used in the following sections. 
      An operator is the APL term for a function which may accept functions 
      as arguments and returns a function. The results of an operator may be 
      bound to a name, used directly, or passed to other operators as arguments. 
      A Namespace is the Dyalog term for a single module of APL code. 
      To create a namespace, a program fixes it from a namespace script, which 
      is the textual representation of the namespace stored as an 
      array or in a file.
    </para>
    <para>
      The LLVM project provides a complete low-level compiler that transforms 
      the LLVM intermediate representation (IR) into native code. It targets 
      multiple architectures, including PTX (for GPU programming), and 
      x86_64 code. It provides many useful low-level optimizations that often 
      require significant effort to implement. This includes function inlining 
      and loop vectorization. It also provides a MCJIT system which enables 
      just-in-time compilation of code in-memory, which suits the needs of 
      the Co-dfns compiler particularly well.
    </para>
    <para>
      When spawning a new parallel computation, in functional languages, 
      often the result of that computation goes into a future. The future 
      serves as a placeholder for the data until the parallel computation 
      completes. Attempting to read the future blocks until the data associated 
      with that future exists. An IVar, or immutable variable, holds at 
      most a single value in its lifetime. When created, it holds no value, 
      and future computations may write at most once into that value. Attempting 
      to read the contents of the variable will block until some computation 
      writes to the variable. Futures and ivars often serve as the 
      synchronizing data structure in deterministic computation for functional 
      programming.
    </para>
  </section>
  <table frame="void">
    <title>APL Syntax Summary</title>
    <thead>
      <tr>
        <th>Expression</th>
        <th colspan="2">Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><literal>f A</literal></td>
        <td colspan="2">Apply <varname>f</varname> to <varname>A</varname>.</td>
      </tr>
      <tr>
        <td><literal>A f B</literal></td>
        <td colspan="2">
          Apply <varname>f</varname> to <varname>A</varname>
          and <varname>B</varname>.
        </td>
      </tr>
      <tr>
        <td><literal>V←Expr</literal></td>
        <td colspan="2">
          Give <literal>Expr</literal> the name <varname>V</varname>.
        </td>
      </tr>
      <tr>
        <td><literal>A[B]</literal></td>
        <td colspan="2">
          Extract array of same shape as <varname>B</varname> from 
          <varname>A</varname> by using each element in <varname>B</varname>
          as an index into <varname>A</varname>.
        </td>
      </tr>
      <tr>
        <td><literal>S1 ⋄ S2</literal></td>
        <td colspan="2">
          Evaluate <literal>S1</literal> and then <literal>S2</literal>.
        </td>
      </tr>
      <tr>
        <td><literal>{ ... }</literal></td>
        <td colspan="2">
          Function definition
        </td>
      </tr>
      <tr>
        <td><varname>⍺</varname></td>
        <td colspan="2">
          The left formal argument in a function definition.
        </td>
      </tr>
      <tr>
        <td><varname>⍵</varname></td>
        <td colspan="2">
          The right formal argument in a function definition.
        </td>
      </tr>
      <tr>
        <td><literal>T:E</literal></td>
        <td colspan="2">
          Inside a function, if <literal>T</literal> then return 
          <literal>E</literal>.
        </td>
      </tr>
      <tr>
        <td><literal>f¨A</literal></td>
        <td colspan="2">
          Apply <varname>f</varname> to each element in <varname>A</varname>.
        </td>
      </tr>
    </tbody>
  </table>
  <section>
    <title>Language Innovations</title>
    <para>
      The dfns language encourages spiritually functional
      data parallel programming; the bulk simd parallelism of
      APL forms the language foundation, not a veneer over mostly 
      serial programs. It does not, however, allow the natural 
      expression of task parallelism. Normal APL operations map well 
      to vector engines, but not to OS threads and concurrent programming. 
    </para>
    <para>
      Traditional solutions to task parallelism in APL bolted on
      concurrency constructs such as mutexes and
      guards, with APL underneath. This approach suffers from the
      same programmability problems that these same constructs have
      in any language, while additionally imposing a significant
      cost on language concision and productivity for
      domain experts. Such constructs serve domain experts little,
      even if the expert might otherwise benefit from a concurrent 
      paradigm. It also unnecessarily complicates the life of a 
      tuning expert.
      Deterministic parallelism somewhat relieves these
      issues by eliminating by construction some undesirable 
      non-determinism in parallel programs. The traditional expression 
      of these features, does not map any more nicely to 
      APL than mutexes, guards, or the like.
    </para>
    <para>
      Task parallelism in APL ought to satisfy two criteria: 
      it should feel like APL, and it should be easy to use safely.
      That is, these constructs should not destroy
      APL's concise expression, nor greatly burden domain experts.
      Co-dfns extends the basic dfns language to enable
      both non-deterministic and deterministic task parallelism
      without requiring any additional syntax, and introducing only
      two new primitives to the language.
    </para>
    <para>
      Firstly, a new literal <literal>⌾</literal> (target) represents the
      new datatype, a single assignment array. A single assignment
      array works like other arrays except that a slot in the array
      receives at most one value in its lifetime. The <literal>⌾</literal>
      value behaves like the empty vector literal <literal>⍬</literal>,
      except that its fill value is a single assignment slot.
      The reshape <literal>S⍴⌾</literal> builds
      a single assignment array of shape <varname>S</varname>, where 
      <varname>S</varname> gives the dimensions of the array. This
      array begins empty, and each slot may be assigned a value at most once. 
    </para>
    <figure>
      <title>Single-assignment Array Example</title>
      <programlisting>A←2 2⍴⌾  ⍝ SA matrix of shape 2 2
A[0;0]←1 ⍝ Assign 0 0 slot to 1
A[0;0]←5 ⍝ Error, multiple writes</programlisting>
    </figure>
    <para>
      Attempting to read a slot in a single assignment array blocks until 
      that slot receives a value. In this way, single assignment arrays 
      deliver IVars in a fashion that completely integrates them with 
      normal APL: they feel like any other normal array during use. 
    </para>
    <para>
      Co-dfns provides concurrent execution through an operator
      <literal>∥</literal>. The expression <literal>F∥</literal> is
      equivalent to the function <varname>F</varname> but when applied 
      returns immediately with a single assignment array whose values 
      will contain the results of executing F concurrently with the rest 
      of the program. Assuming <varname>F</varname> does not deadlock, 
      the array returned is equivalent to the array that would have been 
      returned by the function called without <literal>∥</literal> 
      assuming no error conditions.
    </para>
    <figure>
      <title>Example Naive Parallel Fibonacci</title>
      <programlisting>pfib←{
  1=⍵:1
  2=⍵:1
  (pfib<literal>∥</literal>⍵-1)+(pfib<literal>∥</literal>⍵-2)
}</programlisting>
    </figure>
    <para>
      These two primitives suffice to deliver task parallel computation 
      in the dfns APL dialect. Single assignment arrays allow for 
      synchronization, while the parallel operator enables concurrency. 
      This approach requires no explicit control constructs or syntax.
      These primitives present an attractive alternative to
      traditional approaches because of the implicit and concise expression 
      of concurrency and synchronization. Moreover, by restricting all 
      inter-thread arrays (arrays touched by more than one thread) to single 
      assignment arrays, these constructs also exhibit determinism.
    </para>
  </section>
  <figure pgwide="0">
    <title>Co-dfns Compiler Architecture</title>
    <mediaobject>
      <imageobject>
        <imagedata align="center" width="3.25in" 
                   fileref="architecture.svg" format="SVG" />
      </imageobject>
    </mediaobject>
  </figure>
  <section>
    <title>Implementation</title>
    <para>
      The language of Co-dfns explicitly tries to make concurrency a tool 
      of thought for domain expert programming. The implementation of 
      Co-dfns also has explicit goals:
    </para>
    <orderedlist spacing="compact">
      <listitem>
        <para>
          Enable APL programs to scale to larger problems and modern 
          hardware, including massively parallel systems.
        </para>
      </listitem>
      <listitem>
        <para>
          Make it easy to integrate the compiler into existing APL 
          workflows.
        </para>
      </listitem>
      <listitem>
        <para>
          Support integration with external tools through well documented 
          interfaces and easy to use entry and exit points.
        </para>
      </listitem>
      <listitem>
        <para>
          Support compiled APL that seamlessly integrates with external 
          software products and systems.
        </para>
      </listitem>
    </orderedlist>
    <para>
      At this early stage, the compiler does not realize 
      all of these goals. Nonetheless, the current version does 
      solve all major obstacles to APL compilation, including the handling 
      of operators, nested functions, and possible ambiguity in parsing 
      APL due to the name class of certain variables (that is, whether a variable 
      is bound to a function or an array) in a scalable, performant manner.
    </para>
    <formalpara>
      <title>Architecture</title>
      <para>
        The Co-dfns compiler is itself implemented using dfns in Dyalog APL. 
        This makes the compiler easy to deploy and use. The compiler operates over 
        Namespace scripts to create a Dyalog Namespace, replacing
        the <function>⎕FIX</function> function in the interpreter for anonymous 
        namespaces. Users who wish to compile their code rather than 
        interpret it need only encapsulate their code into a single namespace, 
        and then fix it using the <function>CoDfns.Fix</function> function 
        instead of the <function>⎕FIX</function> function. They can optionally 
        produce an external LL IR file, which is a clang and LLVM compatible 
        object to integrate with other LLVM based compilation objects. 
      </para>
    </formalpara>
    <para>
      The compiler uses a pure-functional, nanopass structure, which divides 
      the compiler into a series of small passes which compose one 
      after another, each one transforming the incoming AST in some specific 
      way. The <function>GenLLVM</function> pass then takes the final AST 
      and converts it into an LLVM module for JITing or exporting to a file. 
    </para>
    <para>
      Being written in dfns, the compiler operates over a linearized XML
      tree that represents the AST, so that each compiler pass consumes
      and produces a valid XML tree that any user can serialize into
      standard format using the <function>⎕XML</function> function,
      easily inserting their own passes or changing the entry or exit
      points of the compiler for various reasons. In addition to being
      functional, which simplifies the design of the compiler, each pass
      tries to emphasize good APL style, focusing on aggregate, data
      parallel operations and minimizing recursion or complex
      operations. As such, the compiler passes have no explicit loops or
      iterations, and they use little to no explicit recursion.
      The degree to which these passes can be expressed using minimal
      explicit control flow suggests that the Co-dfns compiler could
      serve as an excellent benchmark for creating a GPU-run compiler.
      The compiler as a dfns benchmark also suggests places where memory
      handling could improve significantly in Dyalog APL
      and Co-dfns to enable a more functional style of APL program to
      perform well.
    </para>
    <para>
      Finally, the compiler demonstrates the flexibility and generality of the 
      Co-dfns language, in that the compiler itself finds a natural expression 
      therein. It shows how to create small, parallel friendly compiler passes 
      that exhibit none of the traditional complexity in compiler design. APL proves to 
      have a well designed set of primitives that encourages a concise and elegant 
      expression of the tree transformations required to implement a nanopass 
      compiler. This emphasis on aggregate, global operations over trees distinguishes 
      the approach used in Co-dfns from a regular nanopass compiler, 
      which tends to define each pass based on pattern matching and implicit 
      recursion. 
    </para>
    <formalpara>
      <title>Memory management</title>
      <para>
        Systems like Dyalog APL use a garbage collector to manage memory. 
        Garbage collectors liberate programming implementations and languages 
        greatly, and serve as the de facto standard memory management model 
        for most all new languages. This is good. In Co-dfns, however, 
        because the language design enforces a natural stack lifetime on 
        variables and functions, the compiler uses a stack discipline to 
        implement all memory management, completely avoiding the extra 
        complexity and cost of integrating a high-performance garbage collector 
        into the runtime. 
      </para>
    </formalpara>
    <para>
      Interestingly, this decision does not preclude the use of operators, 
      which are higher-order functions in APL which return functions. Functions 
      cannot escape out of a lexical context, which would require indefinite 
      lifetimes of function values. These stack functions permit a wide range of 
      higher-order programming, but require no closure allocation. Indeed, all 
      Co-dfns functions map directly to an LLVM function. Thus, the compiler 
      takes advantage of LLVM optimizations which might otherwise prove more 
      difficult or costly to implement directly, such as inlining. 
    </para>
    <formalpara>
      <title>Fusion</title>
      <para>
        Existing research into parallel system demonstrates the importance and 
        effectiveness of good fusion over certain operators. The Dyalog interpreter 
        performance suffers even in cases where it might due well, because it 
        cannot fuse scalar primitive functions together to leverage modern 
        memory hierarchies. Full scalar function fusion does not yet exist in 
        the Co-dfns compiler, but the use of stack functions above enables the 
        inlining of many other explicit functions, including primtives. Further 
        increments of the compiler development will introduce scalar function 
        fusion.
      </para>
    </formalpara>
  </section>
  <figure>
    <title>Black Scholes Benchmark Code</title>
    <programlisting>r←0.02 ⋄ v←0.03 ⋄ p←÷(○2)*0.5

CNDP←{
  K←÷1+0.2316419×L←|⍵
  R←p×(*(L×L)÷¯2)×{coeff+.×⍵*1+⍳5}¨K
  (1 ¯1)[B]×((0 ¯1)[B←⍵≥0])+R
}

BlackScholes←{
  expRT←*(-r)×T ⋄ vsqrtT←v×T*0.5
  D1←((⍟S÷X)+(r+(v*2)÷2)×T)÷vsqrtT
  D2←D1-vsqrtT
  CD1←CNDP D1 ⋄ CD2←CNDP D2
  R←(S×CD1)-X×expRT×CD2
  R,[0.5]((X×expRT×1-CD2)-S×1-CD1)
}</programlisting>
  </figure>
  <section>
    <title>Evaluation</title>
    <para>
      The Co-dfns compiler does not yet support the entire language, and it 
      does not currently implement many of the intended optimizations designed 
      for it. This makes evaluation challenging, as most benchmarks leverage 
      a fairly wide array of language features and primitives. Notwithstanding
      these challenges, the Co-dfns compiler can compile the Espen Haug 
      Black Scholes calculation. 
    </para>
    <formalpara>
      <title>Blackscholes benchmark</title>
      <para>
        The black scholes formula estimates options pricing, and the 
        implementation of black scholes favors APL Interpreters to a fair 
        degree. Particularly, it requires very little code, and an APL 
        implementation contains very little structural control flow, 
        reducing the interpreter overhead. Moreover, the benchmark deals 
        mostly with scalar calculations over large arrays, for which 
        APL can implement specialized primitives that perform very well.
      </para>
    </formalpara>
    <para>
      The benchmark does a good job of measuring the performance of APL 
      on number crunching applications heavy with scalar computation. It 
      also benefits from good memory and cache locality as the size of 
      the data set increases. 
    </para>
    <formalpara>
      <title>Benchmarking Methodology</title>
      <para>
        To compare the Co-dfns compiler and Dyalog APL, the benchmarking 
        harness simulates as much as possible the intended use case of 
        the compiler. That is, execution of the compiled code should 
        occur as transparently as possible from within the Dyalog APL 
        system, and should not require excessive tooling. 
      </para>
    </formalpara>
    <para>
      The current state of the compiler limits to some degree the level 
      of attainable integration. In particular, the benchmark was 
      compiled offline and linked together as a shared object, rather 
      than taking advantage of LLVM's MCJIT system. To use the shared 
      object from within the Dyalog interpreter, to properly simulate 
      the JIT behavior, a wrapper function written in the interpreter 
      converts the array data structures from that used by the interpreter 
      to that used by the compiled code, and back once the compiled 
      code returns a result. The JIT implementation will remove the need 
      for such explicit wrapper functions.
      The compiled objects were compiled using Clang 3.4 with O3 optimizations, 
      but no other explicit optimization settings. 
    </para>
    <para>
      Each version of the benchmark, one for the interpreter and one for the 
      compiler, used the same APL implementation of the black scholes, though 
      the code used for the compiler was cosmetically tweaked to work around 
      some limitations in the current implementation of the compiler. 
      Each version ran on each data set size three times, and the average 
      of these three computations was taken. Every run manually executed 
      the garbage collector before executing the code.
    </para>
    <para>
      The testing machine used an Intel Core i7-3610QM CPU @ 2.30Ghz with 
      16GB of RAM with Dyalog APL 14.0 Beta 3 on Red Hat Enterprise Linux 
      7.0 Beta. 
    </para>
    <formalpara>
      <title>Results</title>
      <para>
        See the figures for two versions of the same results, one on a 
        logarithmic scale and the other without any logarithmic adjustment. 
        The logarithmic scale demonstrates the performance characteristics 
        of the smaller sizes, while the linear scale demonstrates the 
        proportions of performance factors at large sizes better. 
      </para>
    </formalpara>
    <para>
      Note that the interpreter outperforms the naive, partial implementation 
      of the compiler at low data sizes, but then begins to suffer performance 
      degredation as the size increases. The compiler begins to outperform 
      the interpreter, increasingly so as the sizes of the data grows. 
      The compiler outperforms the interpreter by 26% at the largest data set, 
      without performing any specific optimizations available to it. 
    </para>
    <para>
      The performance of the compiler at the low-end likely indicates the 
      inefficiency of the current approach to injecting and projecting data 
      to and from the compiled code, as this would most significantly influence 
      the results at the low-end. Moreover, the interpreters handling of locality 
      likely contributes to the failure to scale linearly as the data increases. 
      The compiler does a better job of this right now, but could undoubtedly 
      improve a great deal through the use of fusion optimizations. 
    </para>
  </section>
  <figure pgwide="1">
    <title>Black Scholes Benchmark Results</title>
    <inlinemediaobject>
      <imageobject>
        <imagedata align="center" width="3.5in" 
                   fileref="linear.svg" format="SVG" />
      </imageobject>
    </inlinemediaobject>
    <inlinemediaobject>
      <imageobject>
        <imagedata align="center" width="3.5in"
                   fileref="logarithmic.svg" format="SVG" />
      </imageobject>
    </inlinemediaobject>
  </figure>
  <section>
    <title>Related Work</title>
    <para>
      Timothy Budd implemented an APL compiler for a traditional APL system
      that he describes in <quote>An APL Compiler</quote>. The work presents
      a unique and interesting approach to reducing computation on arrays
      by lazily executing computations. Budd's compiler delayed computation
      until the point at which the program requested the value. As in most
      traditional APL compilers, the language of the compiler does not match
      directly with the semantics of normal APL programs of the time. Budd's
      compiler also managed allocation without requiring a garbage collector.
    </para>
    <para>
      Bob Bernecky implemented the APEX compiler, which perhaps best represents
      the traditional APL compiler. It has useful passes, such as data flow
      analysis and static single assignment. Moreover, Bernecky details an
      approach at introducing parallelism into the compiler itself. While the
      APEX compiler is not self-hosting, the efforts to introduce a parallel
      expression of the compiler passes should inform the design of the Co-dfns
      passes and their design. The APEX compiler does suffer from a strong
      number of restrictions, some of which could evaporate given enough
      programmer effort. Both the APEX and Co-dfns compilers share some
      restrictions, such as not allowing the dynamic fixing of new functions
      at runtime. However, much more effort is made to ensure that existing
      dfns programs in Dyalog will run without modification in the Co-dfns compiler
      than the similar compatibility in the APEX compiler.
    </para>
    <para>
      Dyalog has provided a good deal of input into the Co-dfns compiler, and
      so it makes sense that the upcoming release of their interpreter begins
      to implement some of the ideas embedded into the Co-dfns compiler. This
      includes a facility for doing coarse-grained parallelism with futures,
      but does not include any ability to do more refined concurrent operations
      since the interpreter lacks single assignment arrays for synchronization;
      the system itself makes not guarantees when effects occur in parallel.
    </para>
    <para>
      Single-assignment C attempts to deliver a high-level, C-like language 
      that uses arrays as first-class data types. It focuses heavily on a 
      functional paradigm, and on automatically parallelizing code. The same 
      issues of memory copying and array management occur in SAC as in 
      Co-dfns, but SAC is a purely functional language, whereas Co-dfns 
      admits array mutation and variable assignment within a single scope. 
    </para>
    <para>
      The McLAB project implements a compiler and supporting systems for MATLAB 
      code. Like Co-dfns, it provides an explicit intermediate language for 
      work, but goes to a lower level with its own JIT. It also produces 
      Fortran and C code, which are not explicit targets of Co-dfns. 
      The MATLAB language itself differs from Co-dfns, which naturally results
      in differences of approach with McLAB and Co-dfns. Co-dfns adapts the APL 
      language with explicit parallelism constructs, rather than emphasizing 
      automatic parallelization of the runtime primitives. 
    </para>
    <para>
      Languages like X10, Fortress, and Chapel also strive to scale 
      programming to large distributed systems. These system inherit much of 
      their linguistic history from Fortran, Java, and C++, rather than 
      APL. They also emphasize a more object-oriented approach than the 
      array-centric, functional approach of Co-dfns. They also expose much 
      more explicit syntactic constructs for controlling data layout and 
      synchronization, whereas Co-dfns tries to minimize explicit syntax as 
      much as possible. 
    </para>
    <para>
      A number of systems such as Manticore, ZPL, and Accelerate are able to
      provide interesting implementation strategies for array programming,
      each emphasizing different elements. They all take the overall approach
      of altering the language design in favor of making certain features
      prevalent. Accelerate, for instance, lifts rank to the type level,
      meaning that shapes are no longer first class entities. ZPL uses a
      more traditional language but enables predictable data layout for distributed
      computing. Manticore takes advantage of the language and implemenation to
      make heavy use of fusion and fision.
    </para>
    <para>
      Eric Holk's Harlan system takes a unique approach. Targeting the GPU
      explicitly, it tries to introduce traditional programming concepts as
      native concepts on the GPU, so that traditional programs can run reasonably
      on the GPU. This approach, instead of lifting array programming to the
      general-purpose sphere, pulls general-purpose language constructs such as
      ADTs into the GPU and array world through the use of region inference and
      a number of other transformations. It also uses the NanoPass style of
      compiler design and includes a macro system on top of it to reduce the
      number of core forms for the compiler to deal with.
    </para>
  </section>
  <section>
    <title>Moving Forward</title>
    <para>
      Much work still remains to bring the compiler to its firt public version. 
      This includes implementing more optimizations centered around 
      memory management, fusion, and targeting the GPU as well as the CPU. 
      Eventually, the compiler should also host itself, as it is written in 
      dfns. Among the optimizations that have the highest priority are the 
      work of ... to reduce copying of arrays, minimizing allocations and maximizing 
      reuse of memory, and integrating richer and more native scalar function 
      fusion into the compiler. 
    </para>
    <para>
      Further work continues on exploring irregular problem domains, such as
      the compiler itself, and graph algorithms, such as the Graph500 Benchmark. 
      Getting good results on these problems requires additional effort into 
      memory management, such as recognizing shape and types of the array 
      values and doing preallocation of the memory regions before computation. 
      On benchmarks like the Graph500 this can save copying overhead in
      tight loops and make GPU performance much better.
    </para>
  </section>
  <section>
    <title>Conclusion</title>
    <para>
      The Co-dfns compiler, despit the early stages of its development, shows 
      promise for bringing robust scalability to the venerable APL language 
      in the context of modern hardware and platforms, on increasingly large 
      data sets. Unlike many efforts in the array field, the Co-dfns compiler 
      intends from the beginning to be accessible to the domain expert, 
      rather than targeting the computer scientist, and to exhibit suitable 
      industrial strengths for mature applications. The current stage of 
      development can only say so much regarding the future capacity of the 
      compiler, but it does demonstrate the feasibility of the approach and 
      a reasonable expectation of suitable performance gains.
    </para>
  </section>
  <section>
    <title>Acknowledgments</title>
    <para>
      Bob Bernecky provided excellent insight into the state of APL
      compilation. Dyalog, Ltd. has provided gracious funding for the
      development of this compiler. Ryan Newton and Andrew Lumsdaine 
      have greatly aided in directing this research. 
    </para>
  </section>
  <appendix>
    <title>Demo description</title>
    <para>
      Description of the demo of the tool.
    </para>
  </appendix>
</article>
