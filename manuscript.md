# IntroductionModern compiler design relies on recursion and branching execution. Clang's `RecursiveASTVisitor` implements a recursive traversal combined with methods for node operations, essentially a case statement. The Nanopass compiler framework supports compilers as the composition of many small tree transformations defined by dispatching on node type and recuring on children either implicitly or explicitly. This reliance should surprise none: the patterns of control flow exhibited by recursion and branching match very naturally the essence of compiler implementation, tree traversal. What if you could not use branching or recursion?Likely, few would even make the attempt to create a compiler that used neither recursion nor branching. Indeed, what value lives in such an artifact? Such an artifact would certainly challenge and elucidate the construction of compilers in ways not previously seen. Moreover, today's modern architectures exhibit features which suggest that such an approach could also benefit the practical implementation of compilers. Particularly, modern CPU's have vector engines; GPU's generally prove difficult targets for which to implement a traditional compiler; and, distributed systems benefit from more parallel implementations. A vectorized compiler that uses data-parallel operations and simple, straightforward control flow instead of recursion and branching provides insights into tree traversal and avenues for research into the efficiency of compilers and similar programs on modern computing architectures. The Co-dfns compiler transforms a parallel extension of the dfns dialect of APL into C and Cuda code. Uniquely, the implementation is written entirely in Co-dfns. While Co-dfns readily supports recursion and branching, the project pushes the scale and range of APL by implementing the compiler using the native APL vocabulary and traditional array-programming idioms, rather than using recursion or branching. This leads to a very lean, concise, and simple compiler that exhibits very different characteristics both aesthetically and operationally.Modulo parsing, the entire Co-dfns compiler uses the APL array language vocabulary and a nanopass style composition of small, pure functional compiler passes, written with simple data-flow control, to convert between the Co-dfns language, whose AST is encoded as an array, into the target language, a mix of C and Cuda for execution on both the CPU and GPU. The compiler will also target HPX for execution of parallel code on SMP and distributed clusters.The following sections discuss the key implementation insights for each of the major front-end compiler passes for languages that exhibit similiar features to Co-dfns, including lexical scope and higher-order functions. For each pass, the key implementation insight and overall strategy of compilation demonstrates the methods and algorithms used to arrive at a fully vectorizable compiler suitable for execution on the GPU. The exposition of these passes also reveals the concision and compactness of the approach, which accounts for the small amount of code necessary to implement the compiler. Readers may observe the external artifacts and references for the entire compiler source.# ConclusionBy focusing on the use of linearizing passes and by lifting important structural information out of the control flow of the program and into the structure of the data itself, the Co-dfns compiler makes progressive, simple passes that massage the code into its final form, suitable for generation to the target language. This simplicity also results in very compact implementations for each compiler pass, as the mathematically oriented array notations such as APL provide a direct and natural language for these solutions. This concision comes in part because some of the information that might have been explicitly encoded into the control flow of the program instead lives in the AST, which, of course, does not affect the source code of the program directly. The Co-dfns compiler demonstrates not only that a branchless, recursion-free, and vector-friendly compiler can be written, but that such a compiler, while very different, does not require obscure encodings of the same algorithms, instead sitting in its own right with unique algorithms that approach the problem from a different perspective. This presents opportunities both from a pedagogical and practical standpoint. It is not clear that this new perspective will result in faster compilers on GPUs or distributed machines, but at the very least it presents an interesting avenue of research into compiler design and implementation, which results in very compact and concise code  that demonstrates just how generally useful the array oriented programming model could be.